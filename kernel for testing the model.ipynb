{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "numerical-round",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\tirumva2\\.conda\\envs\\tf-115\\lib\\site-packages\\tf_pose\\mobilenet\\mobilenet.py:376: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\tirumva2\\Realtime-Action-Recognition\\utils\\lib_openpose.py:47: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:28:49,537] [TfPoseEstimator] [INFO] loading graph from C:\\Users\\tirumva2\\.conda\\envs\\tf-115\\lib\\site-packages\\tf_pose_data\\graph/mobilenet_thin/graph_opt.pb(default size=656x368)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\tirumva2\\.conda\\envs\\tf-115\\lib\\site-packages\\tf_pose\\estimator.py:358: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\tirumva2\\.conda\\envs\\tf-115\\lib\\site-packages\\tf_pose\\estimator.py:359: The name tf.GraphDef is deprecated. Please use tf.compat.v1.GraphDef instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\tirumva2\\.conda\\envs\\tf-115\\lib\\site-packages\\tf_pose\\estimator.py:377: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\tirumva2\\.conda\\envs\\tf-115\\lib\\site-packages\\tf_pose\\estimator.py:379: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "TfPoseEstimator/MobilenetV1/Conv2d_0/weights\n",
      "TfPoseEstimator/image\n",
      "TfPoseEstimator/MobilenetV1/Conv2d_0/Conv2D\n",
      "TfPoseEstimator/MobilenetV1/Conv2d_0/Conv2D_bn_offset\n",
      "TfPoseEstimator/MobilenetV1/Conv2d_0/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/MobilenetV1/Conv2d_0/Relu\n",
      "TfPoseEstimator/MobilenetV1/Conv2d_1_depthwise/depthwise_weights\n",
      "TfPoseEstimator/MobilenetV1/Conv2d_1_pointwise/weights\n",
      "TfPoseEstimator/MobilenetV1/Conv2d_1_depthwise/depthwise\n",
      "TfPoseEstimator/MobilenetV1/Conv2d_1_pointwise/Conv2D\n",
      "TfPoseEstimator/MobilenetV1/Conv2d_1_pointwise/Conv2D_bn_offset\n",
      "TfPoseEstimator/MobilenetV1/Conv2d_1_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/MobilenetV1/Conv2d_1_pointwise/Relu\n",
      "TfPoseEstimator/MobilenetV1/Conv2d_2_depthwise/depthwise_weights\n",
      "TfPoseEstimator/MobilenetV1/Conv2d_2_pointwise/weights\n",
      "TfPoseEstimator/MobilenetV1/Conv2d_2_depthwise/depthwise\n",
      "TfPoseEstimator/MobilenetV1/Conv2d_2_pointwise/Conv2D\n",
      "TfPoseEstimator/MobilenetV1/Conv2d_2_pointwise/Conv2D_bn_offset\n",
      "TfPoseEstimator/MobilenetV1/Conv2d_2_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/MobilenetV1/Conv2d_2_pointwise/Relu\n",
      "TfPoseEstimator/MobilenetV1/Conv2d_3_depthwise/depthwise_weights\n",
      "TfPoseEstimator/MobilenetV1/Conv2d_3_pointwise/weights\n",
      "TfPoseEstimator/MobilenetV1/Conv2d_3_depthwise/depthwise\n",
      "TfPoseEstimator/MobilenetV1/Conv2d_3_pointwise/Conv2D\n",
      "TfPoseEstimator/MobilenetV1/Conv2d_3_pointwise/Conv2D_bn_offset\n",
      "TfPoseEstimator/MobilenetV1/Conv2d_3_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/MobilenetV1/Conv2d_3_pointwise/Relu\n",
      "TfPoseEstimator/MobilenetV1/Conv2d_4_depthwise/depthwise_weights\n",
      "TfPoseEstimator/MobilenetV1/Conv2d_4_pointwise/weights\n",
      "TfPoseEstimator/MobilenetV1/Conv2d_4_depthwise/depthwise\n",
      "TfPoseEstimator/MobilenetV1/Conv2d_4_pointwise/Conv2D\n",
      "TfPoseEstimator/MobilenetV1/Conv2d_4_pointwise/Conv2D_bn_offset\n",
      "TfPoseEstimator/MobilenetV1/Conv2d_4_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/MobilenetV1/Conv2d_4_pointwise/Relu\n",
      "TfPoseEstimator/MobilenetV1/Conv2d_5_depthwise/depthwise_weights\n",
      "TfPoseEstimator/MobilenetV1/Conv2d_5_pointwise/weights\n",
      "TfPoseEstimator/MobilenetV1/Conv2d_5_depthwise/depthwise\n",
      "TfPoseEstimator/MobilenetV1/Conv2d_5_pointwise/Conv2D\n",
      "TfPoseEstimator/MobilenetV1/Conv2d_5_pointwise/Conv2D_bn_offset\n",
      "TfPoseEstimator/MobilenetV1/Conv2d_5_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/MobilenetV1/Conv2d_5_pointwise/Relu\n",
      "TfPoseEstimator/MobilenetV1/Conv2d_6_depthwise/depthwise_weights\n",
      "TfPoseEstimator/MobilenetV1/Conv2d_6_pointwise/weights\n",
      "TfPoseEstimator/MobilenetV1/Conv2d_6_depthwise/depthwise\n",
      "TfPoseEstimator/MobilenetV1/Conv2d_6_pointwise/Conv2D\n",
      "TfPoseEstimator/MobilenetV1/Conv2d_6_pointwise/Conv2D_bn_offset\n",
      "TfPoseEstimator/MobilenetV1/Conv2d_6_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/MobilenetV1/Conv2d_6_pointwise/Relu\n",
      "TfPoseEstimator/MobilenetV1/Conv2d_7_depthwise/depthwise_weights\n",
      "TfPoseEstimator/MobilenetV1/Conv2d_7_pointwise/weights\n",
      "TfPoseEstimator/MobilenetV1/Conv2d_7_depthwise/depthwise\n",
      "TfPoseEstimator/MobilenetV1/Conv2d_7_pointwise/Conv2D\n",
      "TfPoseEstimator/MobilenetV1/Conv2d_7_pointwise/Conv2D_bn_offset\n",
      "TfPoseEstimator/MobilenetV1/Conv2d_7_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/MobilenetV1/Conv2d_7_pointwise/Relu\n",
      "TfPoseEstimator/MobilenetV1/Conv2d_8_depthwise/depthwise_weights\n",
      "TfPoseEstimator/MobilenetV1/Conv2d_8_pointwise/weights\n",
      "TfPoseEstimator/MobilenetV1/Conv2d_8_depthwise/depthwise\n",
      "TfPoseEstimator/MobilenetV1/Conv2d_8_pointwise/Conv2D\n",
      "TfPoseEstimator/MobilenetV1/Conv2d_8_pointwise/Conv2D_bn_offset\n",
      "TfPoseEstimator/MobilenetV1/Conv2d_8_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/MobilenetV1/Conv2d_8_pointwise/Relu\n",
      "TfPoseEstimator/MobilenetV1/Conv2d_9_depthwise/depthwise_weights\n",
      "TfPoseEstimator/MobilenetV1/Conv2d_9_pointwise/weights\n",
      "TfPoseEstimator/MobilenetV1/Conv2d_9_depthwise/depthwise\n",
      "TfPoseEstimator/MobilenetV1/Conv2d_9_pointwise/Conv2D\n",
      "TfPoseEstimator/MobilenetV1/Conv2d_9_pointwise/Conv2D_bn_offset\n",
      "TfPoseEstimator/MobilenetV1/Conv2d_9_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/MobilenetV1/Conv2d_9_pointwise/Relu\n",
      "TfPoseEstimator/MobilenetV1/Conv2d_10_depthwise/depthwise_weights\n",
      "TfPoseEstimator/MobilenetV1/Conv2d_10_pointwise/weights\n",
      "TfPoseEstimator/MobilenetV1/Conv2d_10_depthwise/depthwise\n",
      "TfPoseEstimator/MobilenetV1/Conv2d_10_pointwise/Conv2D\n",
      "TfPoseEstimator/MobilenetV1/Conv2d_10_pointwise/Conv2D_bn_offset\n",
      "TfPoseEstimator/MobilenetV1/Conv2d_10_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/MobilenetV1/Conv2d_10_pointwise/Relu\n",
      "TfPoseEstimator/MobilenetV1/Conv2d_11_depthwise/depthwise_weights\n",
      "TfPoseEstimator/MobilenetV1/Conv2d_11_pointwise/weights\n",
      "TfPoseEstimator/MobilenetV1/Conv2d_11_depthwise/depthwise\n",
      "TfPoseEstimator/MobilenetV1/Conv2d_11_pointwise/Conv2D\n",
      "TfPoseEstimator/MobilenetV1/Conv2d_11_pointwise/Conv2D_bn_offset\n",
      "TfPoseEstimator/MobilenetV1/Conv2d_11_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/MobilenetV1/Conv2d_11_pointwise/Relu\n",
      "TfPoseEstimator/Conv2d_3_pool\n",
      "TfPoseEstimator/feat_concat/axis\n",
      "TfPoseEstimator/feat_concat\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L1_1_depthwise/depthwise_weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L1_1_pointwise/weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L1_1_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L1_1_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L1_1_pointwise/Conv2D_bn_offset\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L1_1_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L1_1_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L1_2_depthwise/depthwise_weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L1_2_pointwise/weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L1_2_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L1_2_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L1_2_pointwise/Conv2D_bn_offset\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L1_2_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L1_2_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L1_3_depthwise/depthwise_weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L1_3_pointwise/weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L1_3_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L1_3_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L1_3_pointwise/Conv2D_bn_offset\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L1_3_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L1_3_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L1_4_depthwise/depthwise_weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L1_4_pointwise/weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L1_4_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L1_4_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L1_4_pointwise/Conv2D_bn_offset\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L1_4_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L1_4_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L1_5_depthwise/depthwise_weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L1_5_pointwise/weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L1_5_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L1_5_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L1_5_pointwise/Conv2D_bn_offset\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L1_5_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L2_1_depthwise/depthwise_weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L2_1_pointwise/weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L2_1_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L2_1_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L2_1_pointwise/Conv2D_bn_offset\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L2_1_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L2_1_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L2_2_depthwise/depthwise_weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L2_2_pointwise/weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L2_2_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L2_2_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L2_2_pointwise/Conv2D_bn_offset\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L2_2_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L2_2_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L2_3_depthwise/depthwise_weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L2_3_pointwise/weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L2_3_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L2_3_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L2_3_pointwise/Conv2D_bn_offset\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L2_3_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L2_3_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L2_4_depthwise/depthwise_weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L2_4_pointwise/weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L2_4_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L2_4_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L2_4_pointwise/Conv2D_bn_offset\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L2_4_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L2_4_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L2_5_depthwise/depthwise_weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L2_5_pointwise/weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L2_5_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L2_5_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L2_5_pointwise/Conv2D_bn_offset\n",
      "TfPoseEstimator/Openpose/MConv_Stage1_L2_5_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_concat/axis\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_concat\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L1_1_depthwise/depthwise_weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L1_1_pointwise/weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L1_1_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L1_1_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L1_1_pointwise/Conv2D_bn_offset\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L1_1_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L1_1_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L1_2_depthwise/depthwise_weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L1_2_pointwise/weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L1_2_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L1_2_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L1_2_pointwise/Conv2D_bn_offset\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L1_2_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L1_2_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L1_3_depthwise/depthwise_weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L1_3_pointwise/weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L1_3_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L1_3_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L1_3_pointwise/Conv2D_bn_offset\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L1_3_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L1_3_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L1_4_depthwise/depthwise_weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L1_4_pointwise/weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L1_4_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L1_4_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L1_4_pointwise/Conv2D_bn_offset\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L1_4_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L1_4_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L1_5_depthwise/depthwise_weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L1_5_pointwise/weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L1_5_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L1_5_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L1_5_pointwise/Conv2D_bn_offset\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L1_5_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L2_1_depthwise/depthwise_weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L2_1_pointwise/weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L2_1_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L2_1_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L2_1_pointwise/Conv2D_bn_offset\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L2_1_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L2_1_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L2_2_depthwise/depthwise_weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L2_2_pointwise/weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L2_2_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L2_2_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L2_2_pointwise/Conv2D_bn_offset\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L2_2_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L2_2_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L2_3_depthwise/depthwise_weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L2_3_pointwise/weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L2_3_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L2_3_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L2_3_pointwise/Conv2D_bn_offset\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L2_3_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L2_3_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L2_4_depthwise/depthwise_weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L2_4_pointwise/weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L2_4_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L2_4_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L2_4_pointwise/Conv2D_bn_offset\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L2_4_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L2_4_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L2_5_depthwise/depthwise_weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L2_5_pointwise/weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L2_5_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L2_5_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L2_5_pointwise/Conv2D_bn_offset\n",
      "TfPoseEstimator/Openpose/MConv_Stage2_L2_5_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_concat/axis\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_concat\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L1_1_depthwise/depthwise_weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L1_1_pointwise/weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L1_1_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L1_1_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L1_1_pointwise/Conv2D_bn_offset\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L1_1_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L1_1_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L1_2_depthwise/depthwise_weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L1_2_pointwise/weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L1_2_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L1_2_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L1_2_pointwise/Conv2D_bn_offset\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L1_2_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L1_2_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L1_3_depthwise/depthwise_weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L1_3_pointwise/weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L1_3_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L1_3_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L1_3_pointwise/Conv2D_bn_offset\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L1_3_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L1_3_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L1_4_depthwise/depthwise_weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L1_4_pointwise/weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L1_4_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L1_4_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L1_4_pointwise/Conv2D_bn_offset\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L1_4_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L1_4_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L1_5_depthwise/depthwise_weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L1_5_pointwise/weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L1_5_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L1_5_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L1_5_pointwise/Conv2D_bn_offset\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L1_5_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L2_1_depthwise/depthwise_weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L2_1_pointwise/weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L2_1_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L2_1_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L2_1_pointwise/Conv2D_bn_offset\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L2_1_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L2_1_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L2_2_depthwise/depthwise_weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L2_2_pointwise/weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L2_2_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L2_2_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L2_2_pointwise/Conv2D_bn_offset\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L2_2_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L2_2_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L2_3_depthwise/depthwise_weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L2_3_pointwise/weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L2_3_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L2_3_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L2_3_pointwise/Conv2D_bn_offset\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L2_3_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L2_3_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L2_4_depthwise/depthwise_weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L2_4_pointwise/weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L2_4_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L2_4_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L2_4_pointwise/Conv2D_bn_offset\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L2_4_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L2_4_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L2_5_depthwise/depthwise_weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L2_5_pointwise/weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L2_5_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L2_5_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L2_5_pointwise/Conv2D_bn_offset\n",
      "TfPoseEstimator/Openpose/MConv_Stage3_L2_5_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_concat/axis\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_concat\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L1_1_depthwise/depthwise_weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L1_1_pointwise/weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L1_1_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L1_1_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L1_1_pointwise/Conv2D_bn_offset\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L1_1_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L1_1_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L1_2_depthwise/depthwise_weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L1_2_pointwise/weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L1_2_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L1_2_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L1_2_pointwise/Conv2D_bn_offset\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L1_2_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L1_2_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L1_3_depthwise/depthwise_weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L1_3_pointwise/weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L1_3_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L1_3_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L1_3_pointwise/Conv2D_bn_offset\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L1_3_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L1_3_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L1_4_depthwise/depthwise_weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L1_4_pointwise/weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L1_4_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L1_4_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L1_4_pointwise/Conv2D_bn_offset\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L1_4_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L1_4_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L1_5_depthwise/depthwise_weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L1_5_pointwise/weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L1_5_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L1_5_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L1_5_pointwise/Conv2D_bn_offset\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L1_5_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L2_1_depthwise/depthwise_weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L2_1_pointwise/weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L2_1_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L2_1_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L2_1_pointwise/Conv2D_bn_offset\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L2_1_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L2_1_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L2_2_depthwise/depthwise_weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L2_2_pointwise/weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L2_2_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L2_2_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L2_2_pointwise/Conv2D_bn_offset\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L2_2_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L2_2_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L2_3_depthwise/depthwise_weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L2_3_pointwise/weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L2_3_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L2_3_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L2_3_pointwise/Conv2D_bn_offset\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L2_3_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L2_3_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L2_4_depthwise/depthwise_weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L2_4_pointwise/weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L2_4_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L2_4_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L2_4_pointwise/Conv2D_bn_offset\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L2_4_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L2_4_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L2_5_depthwise/depthwise_weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L2_5_pointwise/weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L2_5_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L2_5_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L2_5_pointwise/Conv2D_bn_offset\n",
      "TfPoseEstimator/Openpose/MConv_Stage4_L2_5_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_concat/axis\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_concat\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L1_1_depthwise/depthwise_weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L1_1_pointwise/weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L1_1_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L1_1_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L1_1_pointwise/Conv2D_bn_offset\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L1_1_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L1_1_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L1_2_depthwise/depthwise_weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L1_2_pointwise/weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L1_2_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L1_2_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L1_2_pointwise/Conv2D_bn_offset\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L1_2_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L1_2_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L1_3_depthwise/depthwise_weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L1_3_pointwise/weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L1_3_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L1_3_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L1_3_pointwise/Conv2D_bn_offset\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L1_3_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L1_3_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L1_4_depthwise/depthwise_weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L1_4_pointwise/weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L1_4_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L1_4_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L1_4_pointwise/Conv2D_bn_offset\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L1_4_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L1_4_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L1_5_depthwise/depthwise_weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L1_5_pointwise/weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L1_5_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L1_5_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L1_5_pointwise/Conv2D_bn_offset\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L1_5_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L2_1_depthwise/depthwise_weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L2_1_pointwise/weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L2_1_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L2_1_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L2_1_pointwise/Conv2D_bn_offset\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L2_1_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L2_1_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L2_2_depthwise/depthwise_weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L2_2_pointwise/weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L2_2_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L2_2_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L2_2_pointwise/Conv2D_bn_offset\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L2_2_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L2_2_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L2_3_depthwise/depthwise_weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L2_3_pointwise/weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L2_3_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L2_3_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L2_3_pointwise/Conv2D_bn_offset\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L2_3_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L2_3_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L2_4_depthwise/depthwise_weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L2_4_pointwise/weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L2_4_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L2_4_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L2_4_pointwise/Conv2D_bn_offset\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L2_4_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L2_4_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L2_5_depthwise/depthwise_weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L2_5_pointwise/weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L2_5_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L2_5_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L2_5_pointwise/Conv2D_bn_offset\n",
      "TfPoseEstimator/Openpose/MConv_Stage5_L2_5_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_concat/axis\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_concat\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L1_1_depthwise/depthwise_weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L1_1_pointwise/weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L1_1_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L1_1_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L1_1_pointwise/Conv2D_bn_offset\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L1_1_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L1_1_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L1_2_depthwise/depthwise_weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L1_2_pointwise/weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L1_2_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L1_2_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L1_2_pointwise/Conv2D_bn_offset\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L1_2_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L1_2_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L1_3_depthwise/depthwise_weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L1_3_pointwise/weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L1_3_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L1_3_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L1_3_pointwise/Conv2D_bn_offset\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L1_3_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L1_3_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L1_4_depthwise/depthwise_weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L1_4_pointwise/weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L1_4_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L1_4_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L1_4_pointwise/Conv2D_bn_offset\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L1_4_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L1_4_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L1_5_depthwise/depthwise_weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L1_5_pointwise/weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L1_5_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L1_5_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L1_5_pointwise/Conv2D_bn_offset\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L1_5_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L2_1_depthwise/depthwise_weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L2_1_pointwise/weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L2_1_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L2_1_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L2_1_pointwise/Conv2D_bn_offset\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L2_1_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L2_1_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L2_2_depthwise/depthwise_weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L2_2_pointwise/weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L2_2_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L2_2_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L2_2_pointwise/Conv2D_bn_offset\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L2_2_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L2_2_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L2_3_depthwise/depthwise_weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L2_3_pointwise/weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L2_3_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L2_3_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L2_3_pointwise/Conv2D_bn_offset\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L2_3_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L2_3_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L2_4_depthwise/depthwise_weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L2_4_pointwise/weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L2_4_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L2_4_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L2_4_pointwise/Conv2D_bn_offset\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L2_4_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L2_4_pointwise/Relu\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L2_5_depthwise/depthwise_weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L2_5_pointwise/weights\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L2_5_depthwise/depthwise\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L2_5_pointwise/Conv2D\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L2_5_pointwise/Conv2D_bn_offset\n",
      "TfPoseEstimator/Openpose/MConv_Stage6_L2_5_pointwise/BatchNorm/FusedBatchNorm\n",
      "TfPoseEstimator/Openpose/concat_stage7/axis\n",
      "TfPoseEstimator/Openpose/concat_stage7\n",
      "WARNING:tensorflow:From C:\\Users\\tirumva2\\.conda\\envs\\tf-115\\lib\\site-packages\\tf_pose\\estimator.py:390: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\tirumva2\\.conda\\envs\\tf-115\\lib\\site-packages\\tf_pose\\estimator.py:393: The name tf.image.resize_area is deprecated. Please use tf.compat.v1.image.resize_area instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\tirumva2\\.conda\\envs\\tf-115\\lib\\site-packages\\tf_pose\\tensblur\\smoother.py:95: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\tirumva2\\.conda\\envs\\tf-115\\lib\\site-packages\\tf_pose\\estimator.py:417: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\tirumva2\\.conda\\envs\\tf-115\\lib\\site-packages\\tf_pose\\estimator.py:424: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\tirumva2\\.conda\\envs\\tf-115\\lib\\site-packages\\tf_pose\\estimator.py:427: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\tirumva2\\.conda\\envs\\tf-115\\lib\\site-packages\\tf_pose\\estimator.py:432: The name tf.report_uninitialized_variables is deprecated. Please use tf.compat.v1.report_uninitialized_variables instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:28:51,156] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:28:51,156] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing 0th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:28:51,447] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:28:51,447] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:28:51,449] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:28:51,449] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:28:51,451] [TfPoseEstimator] [INFO] inference image in 0.2942 seconds.\n",
      "[2021-03-16 13:28:51,451] [TfPoseEstimator] [INFO] inference image in 0.2942 seconds.\n",
      "C:\\Users\\tirumva2\\.conda\\envs\\tf-115\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.neighbors.classification module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\tirumva2\\.conda\\envs\\tf-115\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator KNeighborsClassifier from version 0.21.3 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "C:\\Users\\tirumva2\\.conda\\envs\\tf-115\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.svm.classes module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.svm. Anything that cannot be imported from sklearn.svm is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\tirumva2\\.conda\\envs\\tf-115\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator SVC from version 0.21.3 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "C:\\Users\\tirumva2\\.conda\\envs\\tf-115\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.gaussian_process.gpc module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.gaussian_process. Anything that cannot be imported from sklearn.gaussian_process is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\tirumva2\\.conda\\envs\\tf-115\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator GaussianProcessClassifier from version 0.21.3 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "C:\\Users\\tirumva2\\.conda\\envs\\tf-115\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.tree.tree module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.tree. Anything that cannot be imported from sklearn.tree is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\tirumva2\\.conda\\envs\\tf-115\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.21.3 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "C:\\Users\\tirumva2\\.conda\\envs\\tf-115\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.ensemble.forest module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\tirumva2\\.conda\\envs\\tf-115\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 0.21.3 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "C:\\Users\\tirumva2\\.conda\\envs\\tf-115\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.neural_network.multilayer_perceptron module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neural_network. Anything that cannot be imported from sklearn.neural_network is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\tirumva2\\.conda\\envs\\tf-115\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.preprocessing.label module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.preprocessing. Anything that cannot be imported from sklearn.preprocessing is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\tirumva2\\.conda\\envs\\tf-115\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.21.3 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "C:\\Users\\tirumva2\\.conda\\envs\\tf-115\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator MLPClassifier from version 0.21.3 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "C:\\Users\\tirumva2\\.conda\\envs\\tf-115\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.ensemble.weight_boosting module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\tirumva2\\.conda\\envs\\tf-115\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator AdaBoostClassifier from version 0.21.3 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "C:\\Users\\tirumva2\\.conda\\envs\\tf-115\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator GaussianNB from version 0.21.3 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "C:\\Users\\tirumva2\\.conda\\envs\\tf-115\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator QuadraticDiscriminantAnalysis from version 0.21.3 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "C:\\Users\\tirumva2\\.conda\\envs\\tf-115\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.decomposition.pca module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.decomposition. Anything that cannot be imported from sklearn.decomposition is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\tirumva2\\.conda\\envs\\tf-115\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator PCA from version 0.21.3 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "[2021-03-16 13:28:51,480] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:28:51,480] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediced label is : \n",
      "\n",
      "Processing 1th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:28:51,762] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:28:51,762] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:28:51,764] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:28:51,764] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:28:51,766] [TfPoseEstimator] [INFO] inference image in 0.2852 seconds.\n",
      "[2021-03-16 13:28:51,766] [TfPoseEstimator] [INFO] inference image in 0.2852 seconds.\n",
      "[2021-03-16 13:28:51,786] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:28:51,786] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediced label is : \n",
      "\n",
      "Processing 2th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:28:52,053] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:28:52,053] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:28:52,056] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:28:52,056] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:28:52,057] [TfPoseEstimator] [INFO] inference image in 0.2713 seconds.\n",
      "[2021-03-16 13:28:52,057] [TfPoseEstimator] [INFO] inference image in 0.2713 seconds.\n",
      "[2021-03-16 13:28:52,077] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:28:52,077] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediced label is : \n",
      "\n",
      "Processing 3th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:28:52,351] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:28:52,351] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:28:52,354] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:28:52,354] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:28:52,355] [TfPoseEstimator] [INFO] inference image in 0.2783 seconds.\n",
      "[2021-03-16 13:28:52,355] [TfPoseEstimator] [INFO] inference image in 0.2783 seconds.\n",
      "[2021-03-16 13:28:52,373] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:28:52,373] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediced label is : \n",
      "\n",
      "Processing 4th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:28:52,639] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:28:52,639] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:28:52,641] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:28:52,641] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:28:52,642] [TfPoseEstimator] [INFO] inference image in 0.2693 seconds.\n",
      "[2021-03-16 13:28:52,642] [TfPoseEstimator] [INFO] inference image in 0.2693 seconds.\n",
      "[2021-03-16 13:28:52,663] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:28:52,663] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [1.12606442e-01 6.14286114e-01 1.82779073e-01 1.03598256e-06\n",
      " 8.64737779e-02 1.55305137e-04 3.43225464e-03 2.28354425e-05\n",
      " 2.43161244e-04]\n",
      "prediced label is : walk\n",
      "\n",
      "Processing 5th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:28:52,926] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:28:52,926] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:28:52,928] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:28:52,928] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:28:52,929] [TfPoseEstimator] [INFO] inference image in 0.2653 seconds.\n",
      "[2021-03-16 13:28:52,929] [TfPoseEstimator] [INFO] inference image in 0.2653 seconds.\n",
      "[2021-03-16 13:28:52,987] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:28:52,987] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [5.56294300e-01 3.07151805e-01 9.13895384e-02 5.17991386e-07\n",
      " 4.32368996e-02 7.76525695e-05 1.71612734e-03 1.14223959e-05\n",
      " 1.21736985e-04]\n",
      "prediced label is : stand\n",
      "\n",
      "Processing 6th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:28:53,256] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:28:53,256] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:28:53,258] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:28:53,258] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:28:53,260] [TfPoseEstimator] [INFO] inference image in 0.2732 seconds.\n",
      "[2021-03-16 13:28:53,260] [TfPoseEstimator] [INFO] inference image in 0.2732 seconds.\n",
      "[2021-03-16 13:28:53,280] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:28:53,280] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [9.99927276e-01 7.25107616e-05 3.35715586e-09 1.26588167e-13\n",
      " 1.60947815e-08 1.19108026e-12 3.45478981e-11 1.57350254e-08\n",
      " 1.78194757e-07]\n",
      "prediced label is : stand\n",
      "\n",
      "Processing 7th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:28:53,540] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:28:53,540] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:28:53,543] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:28:53,543] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:28:53,544] [TfPoseEstimator] [INFO] inference image in 0.2643 seconds.\n",
      "[2021-03-16 13:28:53,544] [TfPoseEstimator] [INFO] inference image in 0.2643 seconds.\n",
      "[2021-03-16 13:28:53,565] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:28:53,565] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [9.99334877e-01 6.65024342e-04 1.49650440e-08 2.26196699e-13\n",
      " 1.53475200e-08 8.19526534e-13 8.97883341e-11 2.79931150e-08\n",
      " 3.99416829e-08]\n",
      "prediced label is : stand\n",
      "\n",
      "Processing 8th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:28:53,828] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:28:53,828] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:28:53,831] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:28:53,831] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:28:53,832] [TfPoseEstimator] [INFO] inference image in 0.2673 seconds.\n",
      "[2021-03-16 13:28:53,832] [TfPoseEstimator] [INFO] inference image in 0.2673 seconds.\n",
      "[2021-03-16 13:28:53,852] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:28:53,852] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [5.14276628e-01 4.84382491e-01 6.81077930e-04 2.07796287e-08\n",
      " 5.43218081e-04 2.04406494e-06 2.40669795e-05 8.76687666e-05\n",
      " 2.78402457e-06]\n",
      "prediced label is : stand\n",
      "\n",
      "Processing 9th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:28:54,113] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:28:54,113] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:28:54,115] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:28:54,115] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:28:54,116] [TfPoseEstimator] [INFO] inference image in 0.2633 seconds.\n",
      "[2021-03-16 13:28:54,116] [TfPoseEstimator] [INFO] inference image in 0.2633 seconds.\n",
      "[2021-03-16 13:28:54,158] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:28:54,158] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [1.50080768e-02 8.54792548e-01 3.90576410e-02 8.59496916e-07\n",
      " 7.36728461e-02 5.61911920e-03 3.90402174e-03 7.93190452e-03\n",
      " 1.29829900e-05]\n",
      "prediced label is : walk\n",
      "\n",
      "Processing 10th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:28:54,425] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:28:54,425] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:28:54,427] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:28:54,427] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:28:54,428] [TfPoseEstimator] [INFO] inference image in 0.2693 seconds.\n",
      "[2021-03-16 13:28:54,428] [TfPoseEstimator] [INFO] inference image in 0.2693 seconds.\n",
      "[2021-03-16 13:28:54,449] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:28:54,449] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [4.83147845e-04 3.74503144e-01 4.30860089e-02 1.49127686e-06\n",
      " 4.59102755e-01 7.50544290e-02 4.99328567e-03 4.27434575e-02\n",
      " 3.22810296e-05]\n",
      "prediced label is : \n",
      "\n",
      "Processing 11th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:28:54,709] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:28:54,709] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:28:54,712] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:28:54,712] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:28:54,713] [TfPoseEstimator] [INFO] inference image in 0.2643 seconds.\n",
      "[2021-03-16 13:28:54,713] [TfPoseEstimator] [INFO] inference image in 0.2643 seconds.\n",
      "[2021-03-16 13:28:54,734] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:28:54,734] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [2.40413227e-02 3.16308047e-02 1.32434809e-02 8.23299306e-05\n",
      " 4.11368985e-01 1.65236068e-01 1.25774705e-03 3.52537108e-01\n",
      " 6.02154474e-04]\n",
      "prediced label is : \n",
      "\n",
      "Processing 12th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:28:54,997] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:28:54,997] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:28:54,999] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:28:54,999] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:28:55,001] [TfPoseEstimator] [INFO] inference image in 0.2673 seconds.\n",
      "[2021-03-16 13:28:55,001] [TfPoseEstimator] [INFO] inference image in 0.2673 seconds.\n",
      "[2021-03-16 13:28:55,022] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:28:55,022] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [2.38071708e-02 3.15512457e-02 1.79269764e-02 1.19970176e-04\n",
      " 4.22203743e-02 3.79658391e-01 2.41674454e-04 5.03843316e-01\n",
      " 6.30881127e-04]\n",
      "prediced label is : punch\n",
      "\n",
      "Processing 13th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:28:55,283] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:28:55,283] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:28:55,286] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:28:55,286] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:28:55,287] [TfPoseEstimator] [INFO] inference image in 0.2653 seconds.\n",
      "[2021-03-16 13:28:55,287] [TfPoseEstimator] [INFO] inference image in 0.2653 seconds.\n",
      "[2021-03-16 13:28:55,307] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:28:55,307] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [1.32249553e-04 3.44559066e-03 1.08724097e-02 3.97746774e-05\n",
      " 3.48568955e-02 7.25468856e-01 1.11953513e-04 2.25010657e-01\n",
      " 6.16126988e-05]\n",
      "prediced label is : squat\n",
      "\n",
      "Processing 14th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:28:55,571] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:28:55,571] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:28:55,573] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:28:55,573] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:28:55,575] [TfPoseEstimator] [INFO] inference image in 0.2673 seconds.\n",
      "[2021-03-16 13:28:55,575] [TfPoseEstimator] [INFO] inference image in 0.2673 seconds.\n",
      "[2021-03-16 13:28:55,595] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:28:55,595] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [3.26342875e-02 1.26124096e-02 5.92225944e-03 9.00726101e-06\n",
      " 8.21344636e-02 5.23852823e-01 7.79275663e-05 3.42018208e-01\n",
      " 7.38614009e-04]\n",
      "prediced label is : squat\n",
      "\n",
      "Processing 15th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:28:55,862] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:28:55,862] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:28:55,864] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:28:55,864] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:28:55,865] [TfPoseEstimator] [INFO] inference image in 0.2703 seconds.\n",
      "[2021-03-16 13:28:55,865] [TfPoseEstimator] [INFO] inference image in 0.2703 seconds.\n",
      "[2021-03-16 13:28:55,908] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:28:55,908] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [3.56766820e-02 4.33332813e-02 2.04170885e-02 1.67610038e-05\n",
      " 1.56439137e-01 2.28253824e-01 3.33100816e-04 5.14538083e-01\n",
      " 9.92043643e-04]\n",
      "prediced label is : punch\n",
      "\n",
      "Processing 16th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:28:56,173] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:28:56,173] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:28:56,175] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:28:56,175] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:28:56,176] [TfPoseEstimator] [INFO] inference image in 0.2683 seconds.\n",
      "[2021-03-16 13:28:56,176] [TfPoseEstimator] [INFO] inference image in 0.2683 seconds.\n",
      "[2021-03-16 13:28:56,197] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:28:56,197] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [3.05580141e-03 5.29568358e-01 1.71292007e-02 1.01410616e-05\n",
      " 9.23381420e-02 1.46010494e-01 2.91533673e-04 2.11332060e-01\n",
      " 2.64269121e-04]\n",
      "prediced label is : walk\n",
      "\n",
      "Processing 17th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:28:56,471] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:28:56,471] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:28:56,473] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:28:56,473] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:28:56,474] [TfPoseEstimator] [INFO] inference image in 0.2773 seconds.\n",
      "[2021-03-16 13:28:56,474] [TfPoseEstimator] [INFO] inference image in 0.2773 seconds.\n",
      "[2021-03-16 13:28:56,496] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:28:56,496] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [9.62887654e-04 7.10249441e-01 3.43557358e-02 1.11127227e-06\n",
      " 2.52032718e-01 7.02420717e-04 1.67492536e-03 1.97706748e-05\n",
      " 9.88892496e-07]\n",
      "prediced label is : walk\n",
      "\n",
      "Processing 18th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:28:56,767] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:28:56,767] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:28:56,769] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:28:56,769] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:28:56,769] [TfPoseEstimator] [INFO] inference image in 0.2733 seconds.\n",
      "[2021-03-16 13:28:56,769] [TfPoseEstimator] [INFO] inference image in 0.2733 seconds.\n",
      "[2021-03-16 13:28:56,790] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:28:56,790] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [4.97715987e-01 2.12563150e-01 3.34452766e-02 2.06262658e-07\n",
      " 2.53818693e-01 7.12489230e-04 1.65465355e-03 1.33356550e-05\n",
      " 7.62093438e-05]\n",
      "prediced label is : \n",
      "\n",
      "Processing 19th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:28:57,065] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:28:57,065] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:28:57,068] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:28:57,068] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:28:57,069] [TfPoseEstimator] [INFO] inference image in 0.2783 seconds.\n",
      "[2021-03-16 13:28:57,069] [TfPoseEstimator] [INFO] inference image in 0.2783 seconds.\n",
      "[2021-03-16 13:28:57,093] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:28:57,093] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [5.76265107e-01 4.20643842e-01 3.21174126e-04 8.39532467e-09\n",
      " 1.79442830e-03 1.03836596e-05 2.29478145e-05 5.19199209e-07\n",
      " 9.41589651e-04]\n",
      "prediced label is : stand\n",
      "\n",
      "Processing 20th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:28:57,372] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:28:57,372] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:28:57,374] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:28:57,374] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:28:57,376] [TfPoseEstimator] [INFO] inference image in 0.2832 seconds.\n",
      "[2021-03-16 13:28:57,376] [TfPoseEstimator] [INFO] inference image in 0.2832 seconds.\n",
      "[2021-03-16 13:28:57,396] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:28:57,396] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [7.95119842e-02 9.19514948e-01 7.70238452e-05 7.96811308e-09\n",
      " 7.37305433e-06 1.93583224e-10 2.22969627e-05 1.35192444e-08\n",
      " 8.66352229e-04]\n",
      "prediced label is : walk\n",
      "\n",
      "Processing 21th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:28:57,668] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:28:57,668] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:28:57,671] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:28:57,671] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:28:57,672] [TfPoseEstimator] [INFO] inference image in 0.2763 seconds.\n",
      "[2021-03-16 13:28:57,672] [TfPoseEstimator] [INFO] inference image in 0.2763 seconds.\n",
      "[2021-03-16 13:28:57,692] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:28:57,692] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [1.26819886e-10 9.99998219e-01 3.05009239e-07 1.08043186e-11\n",
      " 5.21007226e-12 1.56818486e-17 1.47567671e-06 2.39333466e-13\n",
      " 4.57988424e-10]\n",
      "prediced label is : walk\n",
      "\n",
      "Processing 22th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:28:57,958] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:28:57,958] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:28:57,960] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:28:57,960] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:28:57,961] [TfPoseEstimator] [INFO] inference image in 0.2693 seconds.\n",
      "[2021-03-16 13:28:57,961] [TfPoseEstimator] [INFO] inference image in 0.2693 seconds.\n",
      "[2021-03-16 13:28:57,982] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:28:57,982] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [8.30094680e-09 9.99994299e-01 1.43888910e-07 4.29356916e-12\n",
      " 2.54356798e-11 2.25643510e-17 5.45541738e-06 4.11424856e-13\n",
      " 9.35109827e-08]\n",
      "prediced label is : walk\n",
      "\n",
      "Processing 23th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:28:58,256] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:28:58,256] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:28:58,258] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:28:58,258] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:28:58,259] [TfPoseEstimator] [INFO] inference image in 0.2763 seconds.\n",
      "[2021-03-16 13:28:58,259] [TfPoseEstimator] [INFO] inference image in 0.2763 seconds.\n",
      "[2021-03-16 13:28:58,279] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:28:58,279] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [8.75532006e-09 9.99994645e-01 1.27566123e-07 3.04769771e-12\n",
      " 2.28961514e-11 1.52585144e-17 5.12443096e-06 2.36313239e-13\n",
      " 9.37261590e-08]\n",
      "prediced label is : walk\n",
      "\n",
      "Processing 24th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:28:58,540] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:28:58,540] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:28:58,542] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:28:58,542] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:28:58,544] [TfPoseEstimator] [INFO] inference image in 0.2643 seconds.\n",
      "[2021-03-16 13:28:58,544] [TfPoseEstimator] [INFO] inference image in 0.2643 seconds.\n",
      "[2021-03-16 13:28:58,567] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:28:58,567] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [6.19917910e-10 9.99998288e-01 7.37923757e-08 3.43425100e-13\n",
      " 1.94639838e-12 2.96047817e-19 1.63645007e-06 5.57052045e-15\n",
      " 7.20530264e-10]\n",
      "prediced label is : walk\n",
      "\n",
      "Processing 25th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:28:58,833] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:28:58,833] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:28:58,836] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:28:58,836] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:28:58,837] [TfPoseEstimator] [INFO] inference image in 0.2703 seconds.\n",
      "[2021-03-16 13:28:58,837] [TfPoseEstimator] [INFO] inference image in 0.2703 seconds.\n",
      "[2021-03-16 13:28:58,857] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:28:58,857] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [6.42023715e-11 9.99980220e-01 2.59114238e-07 7.28892972e-13\n",
      " 1.13579440e-12 2.95717567e-19 1.95194522e-05 1.16610509e-15\n",
      " 1.51432355e-09]\n",
      "prediced label is : walk\n",
      "\n",
      "Processing 26th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:28:59,119] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:28:59,119] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:28:59,122] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:28:59,122] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:28:59,123] [TfPoseEstimator] [INFO] inference image in 0.2663 seconds.\n",
      "[2021-03-16 13:28:59,123] [TfPoseEstimator] [INFO] inference image in 0.2663 seconds.\n",
      "[2021-03-16 13:28:59,144] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:28:59,144] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [1.78874985e-13 9.60560819e-01 4.00827663e-07 6.32252619e-13\n",
      " 2.20895951e-13 1.08127450e-19 3.94387787e-02 9.93916610e-17\n",
      " 1.04163170e-09]\n",
      "prediced label is : walk\n",
      "\n",
      "Processing 27th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:28:59,412] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:28:59,412] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:28:59,415] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:28:59,415] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:28:59,416] [TfPoseEstimator] [INFO] inference image in 0.2723 seconds.\n",
      "[2021-03-16 13:28:59,416] [TfPoseEstimator] [INFO] inference image in 0.2723 seconds.\n",
      "[2021-03-16 13:28:59,437] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:28:59,437] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [9.65020219e-22 9.27661692e-01 3.40544477e-07 1.31378917e-12\n",
      " 9.42006219e-15 1.15779482e-20 7.23379670e-02 1.39209791e-19\n",
      " 9.59529313e-13]\n",
      "prediced label is : walk\n",
      "\n",
      "Processing 28th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:28:59,699] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:28:59,699] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:28:59,701] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:28:59,701] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:28:59,702] [TfPoseEstimator] [INFO] inference image in 0.2643 seconds.\n",
      "[2021-03-16 13:28:59,702] [TfPoseEstimator] [INFO] inference image in 0.2643 seconds.\n",
      "[2021-03-16 13:28:59,737] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:28:59,737] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [2.08028466e-22 6.01528491e-01 3.40240224e-06 5.01287124e-11\n",
      " 6.02088424e-14 5.20609591e-18 3.98468106e-01 4.31992012e-19\n",
      " 1.38256409e-12]\n",
      "prediced label is : walk\n",
      "\n",
      "Processing 29th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:29:00,008] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:00,008] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:00,010] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:29:00,010] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:29:00,012] [TfPoseEstimator] [INFO] inference image in 0.2753 seconds.\n",
      "[2021-03-16 13:29:00,012] [TfPoseEstimator] [INFO] inference image in 0.2753 seconds.\n",
      "[2021-03-16 13:29:00,032] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:29:00,032] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [3.32650632e-18 6.13145376e-01 5.94140224e-06 8.19122222e-11\n",
      " 2.88931689e-13 7.13139445e-18 3.86848682e-01 5.95545724e-18\n",
      " 1.98554757e-10]\n",
      "prediced label is : walk\n",
      "\n",
      "Processing 30th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:29:00,293] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:00,293] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:00,296] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:29:00,296] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:29:00,297] [TfPoseEstimator] [INFO] inference image in 0.2653 seconds.\n",
      "[2021-03-16 13:29:00,297] [TfPoseEstimator] [INFO] inference image in 0.2653 seconds.\n",
      "[2021-03-16 13:29:00,319] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:29:00,319] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [4.87862468e-16 9.72398912e-01 3.14599349e-06 5.14272553e-11\n",
      " 1.22291860e-12 4.95077474e-18 2.75979412e-02 5.01186137e-17\n",
      " 4.60775567e-10]\n",
      "prediced label is : walk\n",
      "\n",
      "Processing 31th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:29:00,582] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:00,582] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:00,585] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:29:00,585] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:29:00,586] [TfPoseEstimator] [INFO] inference image in 0.2683 seconds.\n",
      "[2021-03-16 13:29:00,586] [TfPoseEstimator] [INFO] inference image in 0.2683 seconds.\n",
      "[2021-03-16 13:29:00,606] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:29:00,606] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [5.17929968e-15 9.92741090e-01 3.91405437e-06 4.92395457e-11\n",
      " 2.61718122e-12 1.98594023e-17 7.25499549e-03 1.65331111e-16\n",
      " 6.34683203e-10]\n",
      "prediced label is : walk\n",
      "\n",
      "Processing 32th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:29:00,869] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:00,869] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:00,872] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:29:00,872] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:29:00,873] [TfPoseEstimator] [INFO] inference image in 0.2663 seconds.\n",
      "[2021-03-16 13:29:00,873] [TfPoseEstimator] [INFO] inference image in 0.2663 seconds.\n",
      "[2021-03-16 13:29:00,892] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:29:00,892] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [5.01282092e-15 9.98241900e-01 3.84876365e-06 4.33921982e-11\n",
      " 1.91958794e-12 2.28429180e-17 1.75425029e-03 6.75196812e-16\n",
      " 5.31487096e-10]\n",
      "prediced label is : walk\n",
      "\n",
      "Processing 33th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:29:01,155] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:01,155] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:01,158] [TfPoseEstimator] [DEBUG] estimate time=0.00199\n",
      "[2021-03-16 13:29:01,158] [TfPoseEstimator] [DEBUG] estimate time=0.00199\n",
      "[2021-03-16 13:29:01,159] [TfPoseEstimator] [INFO] inference image in 0.2663 seconds.\n",
      "[2021-03-16 13:29:01,159] [TfPoseEstimator] [INFO] inference image in 0.2663 seconds.\n",
      "[2021-03-16 13:29:01,179] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:29:01,179] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [7.45921465e-15 9.97753474e-01 3.78171979e-06 1.75203008e-11\n",
      " 2.04526038e-12 5.13263099e-17 2.24273603e-03 1.02177963e-14\n",
      " 7.93390340e-09]\n",
      "prediced label is : walk\n",
      "\n",
      "Processing 34th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:29:01,439] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:01,439] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:01,441] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:29:01,441] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:29:01,443] [TfPoseEstimator] [INFO] inference image in 0.2643 seconds.\n",
      "[2021-03-16 13:29:01,443] [TfPoseEstimator] [INFO] inference image in 0.2643 seconds.\n",
      "[2021-03-16 13:29:01,463] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:29:01,463] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [1.65308446e-12 9.97758952e-01 7.57690929e-06 1.03401107e-11\n",
      " 6.29078951e-11 2.32965407e-16 2.23346014e-03 1.95188080e-14\n",
      " 1.06594226e-08]\n",
      "prediced label is : walk\n",
      "\n",
      "Processing 35th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:29:01,725] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:01,725] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:01,727] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:29:01,727] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:29:01,728] [TfPoseEstimator] [INFO] inference image in 0.2653 seconds.\n",
      "[2021-03-16 13:29:01,728] [TfPoseEstimator] [INFO] inference image in 0.2653 seconds.\n",
      "[2021-03-16 13:29:01,749] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:29:01,749] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [8.64368730e-12 9.99160334e-01 4.85428106e-05 6.40429326e-11\n",
      " 6.15420209e-11 3.16439022e-16 7.90821257e-04 4.76750484e-13\n",
      " 3.01856063e-07]\n",
      "prediced label is : walk\n",
      "\n",
      "Processing 36th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:29:02,012] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:02,012] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:02,014] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:29:02,014] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:29:02,015] [TfPoseEstimator] [INFO] inference image in 0.2663 seconds.\n",
      "[2021-03-16 13:29:02,015] [TfPoseEstimator] [INFO] inference image in 0.2663 seconds.\n",
      "[2021-03-16 13:29:02,037] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:29:02,037] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [7.05665645e-05 9.99873532e-01 4.61682447e-05 1.51250363e-09\n",
      " 3.05960508e-11 1.01429049e-14 9.53798341e-07 9.61338075e-09\n",
      " 8.76852358e-06]\n",
      "prediced label is : walk\n",
      "\n",
      "Processing 37th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:29:02,300] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:02,300] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:02,302] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:29:02,302] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:29:02,304] [TfPoseEstimator] [INFO] inference image in 0.2663 seconds.\n",
      "[2021-03-16 13:29:02,304] [TfPoseEstimator] [INFO] inference image in 0.2663 seconds.\n",
      "[2021-03-16 13:29:02,324] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:29:02,324] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [7.05820452e-05 9.99917015e-01 3.90706396e-06 2.04352846e-09\n",
      " 3.14155027e-11 1.41311865e-14 5.40153176e-09 1.29983494e-08\n",
      " 8.47504490e-06]\n",
      "prediced label is : walk\n",
      "\n",
      "Processing 38th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:29:02,588] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:02,588] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:02,590] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:29:02,590] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:29:02,591] [TfPoseEstimator] [INFO] inference image in 0.2673 seconds.\n",
      "[2021-03-16 13:29:02,591] [TfPoseEstimator] [INFO] inference image in 0.2673 seconds.\n",
      "[2021-03-16 13:29:02,613] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:29:02,613] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [4.99380151e-01 5.00614478e-01 2.24887027e-06 5.94674462e-10\n",
      " 1.64312569e-06 1.28040546e-09 3.82044359e-09 1.04147078e-06\n",
      " 4.31422245e-07]\n",
      "prediced label is : walk\n",
      "\n",
      "Processing 39th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:29:02,876] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:02,876] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:02,878] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:29:02,878] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:29:02,879] [TfPoseEstimator] [INFO] inference image in 0.2663 seconds.\n",
      "[2021-03-16 13:29:02,879] [TfPoseEstimator] [INFO] inference image in 0.2663 seconds.\n",
      "[2021-03-16 13:29:02,900] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:29:02,900] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [9.85443301e-01 1.45532915e-02 2.02995436e-07 5.37349440e-12\n",
      " 1.64548785e-06 1.28046953e-09 2.01677272e-09 1.08748339e-06\n",
      " 4.68571097e-07]\n",
      "prediced label is : stand\n",
      "\n",
      "Processing 40th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:29:03,166] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:03,166] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:03,170] [TfPoseEstimator] [DEBUG] estimate time=0.00299\n",
      "[2021-03-16 13:29:03,170] [TfPoseEstimator] [DEBUG] estimate time=0.00299\n",
      "[2021-03-16 13:29:03,172] [TfPoseEstimator] [INFO] inference image in 0.2723 seconds.\n",
      "[2021-03-16 13:29:03,172] [TfPoseEstimator] [INFO] inference image in 0.2723 seconds.\n",
      "[2021-03-16 13:29:03,194] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:29:03,194] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [9.75249267e-01 2.47426322e-02 2.49562144e-07 4.96255682e-12\n",
      " 8.63151882e-08 1.33268996e-10 5.69335028e-10 7.16114923e-06\n",
      " 6.03486312e-07]\n",
      "prediced label is : stand\n",
      "\n",
      "Processing 41th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:29:03,457] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:03,457] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:03,459] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:29:03,459] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:29:03,461] [TfPoseEstimator] [INFO] inference image in 0.2663 seconds.\n",
      "[2021-03-16 13:29:03,461] [TfPoseEstimator] [INFO] inference image in 0.2663 seconds.\n",
      "[2021-03-16 13:29:03,481] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:29:03,481] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [5.63375937e-01 4.36411589e-01 7.94513119e-06 1.26243917e-10\n",
      " 2.57365280e-07 1.24482157e-09 1.39224088e-08 1.99889534e-04\n",
      " 4.36738867e-06]\n",
      "prediced label is : stand\n",
      "\n",
      "Processing 42th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:29:03,741] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:03,741] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:03,744] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:29:03,744] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:29:03,745] [TfPoseEstimator] [INFO] inference image in 0.2643 seconds.\n",
      "[2021-03-16 13:29:03,745] [TfPoseEstimator] [INFO] inference image in 0.2643 seconds.\n",
      "[2021-03-16 13:29:03,766] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:29:03,766] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [9.50669589e-02 8.42974703e-01 1.85661013e-02 6.23354575e-08\n",
      " 4.64978486e-03 7.50781101e-04 4.55393515e-05 3.79242579e-02\n",
      " 2.18110339e-05]\n",
      "prediced label is : walk\n",
      "\n",
      "Processing 43th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:29:04,028] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:04,028] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:04,030] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:29:04,030] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:29:04,031] [TfPoseEstimator] [INFO] inference image in 0.2653 seconds.\n",
      "[2021-03-16 13:29:04,031] [TfPoseEstimator] [INFO] inference image in 0.2653 seconds.\n",
      "[2021-03-16 13:29:04,052] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:29:04,052] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [5.16686933e-01 4.20871971e-01 1.85618015e-02 6.27419865e-08\n",
      " 4.67036360e-03 7.50952947e-04 4.56170569e-05 3.83734123e-02\n",
      " 3.88860521e-05]\n",
      "prediced label is : stand\n",
      "\n",
      "Processing 44th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:29:04,315] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:04,315] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:04,317] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:29:04,317] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:29:04,318] [TfPoseEstimator] [INFO] inference image in 0.2663 seconds.\n",
      "[2021-03-16 13:29:04,318] [TfPoseEstimator] [INFO] inference image in 0.2663 seconds.\n",
      "[2021-03-16 13:29:04,339] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:29:04,339] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [4.99508562e-01 2.05825828e-02 1.99904557e-03 9.01312998e-07\n",
      " 5.02656469e-03 8.81424479e-03 2.71224081e-05 4.63860246e-01\n",
      " 1.80729754e-04]\n",
      "prediced label is : \n",
      "\n",
      "Processing 45th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:29:04,604] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:04,604] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:04,606] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:29:04,606] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:29:04,607] [TfPoseEstimator] [INFO] inference image in 0.2673 seconds.\n",
      "[2021-03-16 13:29:04,607] [TfPoseEstimator] [INFO] inference image in 0.2673 seconds.\n",
      "[2021-03-16 13:29:04,627] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:29:04,627] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [4.44492655e-03 1.72643073e-02 3.11392564e-03 3.70045666e-06\n",
      " 9.41903910e-02 2.19419635e-01 7.69822704e-05 6.61291488e-01\n",
      " 1.94644325e-04]\n",
      "prediced label is : punch\n",
      "\n",
      "Processing 46th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:29:04,890] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:04,890] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:04,892] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:29:04,892] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:29:04,893] [TfPoseEstimator] [INFO] inference image in 0.2653 seconds.\n",
      "[2021-03-16 13:29:04,893] [TfPoseEstimator] [INFO] inference image in 0.2653 seconds.\n",
      "[2021-03-16 13:29:04,914] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:29:04,914] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [1.41200744e-03 7.65934177e-04 1.65409588e-03 4.45810470e-06\n",
      " 9.57815606e-02 2.25732380e-01 5.70617800e-05 6.74410724e-01\n",
      " 1.81777773e-04]\n",
      "prediced label is : punch\n",
      "\n",
      "Processing 47th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:29:05,177] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:05,177] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:05,179] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:29:05,179] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:29:05,180] [TfPoseEstimator] [INFO] inference image in 0.2663 seconds.\n",
      "[2021-03-16 13:29:05,180] [TfPoseEstimator] [INFO] inference image in 0.2663 seconds.\n",
      "[2021-03-16 13:29:05,201] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:29:05,201] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [7.23998087e-04 6.16317557e-04 8.88588421e-04 2.10927587e-06\n",
      " 1.90114933e-02 1.16776655e-01 9.35254392e-06 8.61795318e-01\n",
      " 1.76167396e-04]\n",
      "prediced label is : punch\n",
      "\n",
      "Processing 48th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:29:05,462] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:05,462] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:05,465] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:29:05,465] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:29:05,466] [TfPoseEstimator] [INFO] inference image in 0.2653 seconds.\n",
      "[2021-03-16 13:29:05,466] [TfPoseEstimator] [INFO] inference image in 0.2653 seconds.\n",
      "[2021-03-16 13:29:05,487] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:29:05,487] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [2.02538050e-04 1.18281743e-03 1.21609165e-03 9.41181563e-06\n",
      " 1.50808826e-02 1.16355597e-01 8.51891057e-06 8.65869708e-01\n",
      " 7.44347914e-05]\n",
      "prediced label is : punch\n",
      "\n",
      "Processing 49th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:29:05,747] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:05,747] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:05,749] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:29:05,749] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:29:05,750] [TfPoseEstimator] [INFO] inference image in 0.2633 seconds.\n",
      "[2021-03-16 13:29:05,750] [TfPoseEstimator] [INFO] inference image in 0.2633 seconds.\n",
      "[2021-03-16 13:29:05,770] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:29:05,770] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [1.44375600e-04 4.84446565e-01 3.61141082e-03 1.02409421e-05\n",
      " 2.67578623e-03 1.47208926e-02 1.25079514e-03 4.93086052e-01\n",
      " 5.38812378e-05]\n",
      "prediced label is : \n",
      "\n",
      "Processing 50th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:29:06,035] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:06,035] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:06,037] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:29:06,037] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:29:06,038] [TfPoseEstimator] [INFO] inference image in 0.2673 seconds.\n",
      "[2021-03-16 13:29:06,038] [TfPoseEstimator] [INFO] inference image in 0.2673 seconds.\n",
      "[2021-03-16 13:29:06,059] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:29:06,059] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [1.57110958e-02 9.55398374e-01 4.71817207e-03 1.98954156e-06\n",
      " 9.23226182e-03 9.38176780e-05 1.64123577e-03 1.31800344e-02\n",
      " 2.30186002e-05]\n",
      "prediced label is : walk\n",
      "\n",
      "Processing 51th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:29:06,319] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:06,319] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:06,322] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:29:06,322] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:29:06,323] [TfPoseEstimator] [INFO] inference image in 0.2643 seconds.\n",
      "[2021-03-16 13:29:06,323] [TfPoseEstimator] [INFO] inference image in 0.2643 seconds.\n",
      "[2021-03-16 13:29:06,343] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:29:06,343] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [1.57170549e-02 9.67981249e-01 6.01016580e-03 1.25763685e-06\n",
      " 9.22392387e-03 7.89473618e-05 4.03316849e-04 5.06159722e-04\n",
      " 7.79249026e-05]\n",
      "prediced label is : walk\n",
      "\n",
      "Processing 52th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:29:06,604] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:06,604] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:06,607] [TfPoseEstimator] [DEBUG] estimate time=0.00299\n",
      "[2021-03-16 13:29:06,607] [TfPoseEstimator] [DEBUG] estimate time=0.00299\n",
      "[2021-03-16 13:29:06,608] [TfPoseEstimator] [INFO] inference image in 0.2653 seconds.\n",
      "[2021-03-16 13:29:06,608] [TfPoseEstimator] [INFO] inference image in 0.2653 seconds.\n",
      "[2021-03-16 13:29:06,628] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:29:06,628] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [4.56816952e-01 5.38970635e-01 4.04056356e-03 5.48105822e-07\n",
      " 1.12625179e-06 2.62973079e-07 6.66400583e-06 2.40993529e-07\n",
      " 1.63007681e-04]\n",
      "prediced label is : walk\n",
      "\n",
      "Processing 53th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:29:06,890] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:06,890] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:06,892] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:29:06,892] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:29:06,893] [TfPoseEstimator] [INFO] inference image in 0.2653 seconds.\n",
      "[2021-03-16 13:29:06,893] [TfPoseEstimator] [INFO] inference image in 0.2653 seconds.\n",
      "[2021-03-16 13:29:06,914] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:29:06,914] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [4.56810991e-01 5.43088250e-01 4.57804634e-07 4.21540335e-11\n",
      " 4.94510361e-08 2.66096613e-13 7.78585607e-07 3.48805041e-09\n",
      " 9.94691856e-05]\n",
      "prediced label is : walk\n",
      "\n",
      "Processing 54th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:29:07,178] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:07,178] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:07,180] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:29:07,180] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:29:07,181] [TfPoseEstimator] [INFO] inference image in 0.2663 seconds.\n",
      "[2021-03-16 13:29:07,181] [TfPoseEstimator] [INFO] inference image in 0.2663 seconds.\n",
      "[2021-03-16 13:29:07,202] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:29:07,202] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [1.42564323e-15 9.99991286e-01 1.16202994e-08 1.13591170e-12\n",
      " 2.38489597e-14 2.62512431e-20 8.70201314e-06 1.12278536e-15\n",
      " 9.86955761e-12]\n",
      "prediced label is : walk\n",
      "\n",
      "Processing 55th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:29:07,465] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:07,465] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:07,468] [TfPoseEstimator] [DEBUG] estimate time=0.00199\n",
      "[2021-03-16 13:29:07,468] [TfPoseEstimator] [DEBUG] estimate time=0.00199\n",
      "[2021-03-16 13:29:07,469] [TfPoseEstimator] [INFO] inference image in 0.2673 seconds.\n",
      "[2021-03-16 13:29:07,469] [TfPoseEstimator] [INFO] inference image in 0.2673 seconds.\n",
      "[2021-03-16 13:29:07,489] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:29:07,489] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [3.44098455e-05 9.96250429e-01 2.76079951e-04 1.48595845e-11\n",
      " 3.67653270e-07 1.56668307e-13 3.43815773e-03 2.46088151e-12\n",
      " 5.56078898e-07]\n",
      "prediced label is : walk\n",
      "\n",
      "Processing 56th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:29:07,756] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:07,756] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:07,758] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:29:07,758] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:29:07,760] [TfPoseEstimator] [INFO] inference image in 0.2712 seconds.\n",
      "[2021-03-16 13:29:07,760] [TfPoseEstimator] [INFO] inference image in 0.2712 seconds.\n",
      "[2021-03-16 13:29:07,780] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:29:07,780] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [3.44098455e-05 9.96256002e-01 2.76080644e-04 1.47746484e-11\n",
      " 3.67653251e-07 1.56668286e-13 3.43258382e-03 2.46057137e-12\n",
      " 5.56077831e-07]\n",
      "prediced label is : walk\n",
      "\n",
      "Processing 57th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:29:08,043] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:08,043] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:08,046] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:29:08,046] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:29:08,047] [TfPoseEstimator] [INFO] inference image in 0.2673 seconds.\n",
      "[2021-03-16 13:29:08,047] [TfPoseEstimator] [INFO] inference image in 0.2673 seconds.\n",
      "[2021-03-16 13:29:08,068] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:29:08,068] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [5.99486585e-08 9.95758612e-01 1.22527589e-04 1.01803693e-10\n",
      " 1.05003714e-08 1.48316996e-14 4.11861923e-03 6.82399325e-13\n",
      " 1.70989565e-07]\n",
      "prediced label is : walk\n",
      "\n",
      "Processing 58th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:29:08,333] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:08,333] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:08,335] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:29:08,335] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:29:08,336] [TfPoseEstimator] [INFO] inference image in 0.2673 seconds.\n",
      "[2021-03-16 13:29:08,336] [TfPoseEstimator] [INFO] inference image in 0.2673 seconds.\n",
      "[2021-03-16 13:29:08,358] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:29:08,358] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [5.99486585e-08 4.95761031e-01 1.27280180e-04 1.01959110e-10\n",
      " 1.05013054e-08 7.85871428e-13 5.04111447e-01 6.82440758e-13\n",
      " 1.70989507e-07]\n",
      "prediced label is : kick\n",
      "\n",
      "Processing 59th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:29:08,619] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:08,619] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:08,621] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:29:08,621] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:29:08,623] [TfPoseEstimator] [INFO] inference image in 0.2653 seconds.\n",
      "[2021-03-16 13:29:08,623] [TfPoseEstimator] [INFO] inference image in 0.2653 seconds.\n",
      "[2021-03-16 13:29:08,643] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:29:08,643] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [6.36211777e-10 4.50370133e-01 3.98494307e-03 2.69663195e-08\n",
      " 3.96692853e-06 1.22812829e-07 5.45627351e-01 3.83362794e-06\n",
      " 9.62202949e-06]\n",
      "prediced label is : kick\n",
      "\n",
      "Processing 60th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:29:08,904] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:08,904] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:08,906] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:29:08,906] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:29:08,907] [TfPoseEstimator] [INFO] inference image in 0.2643 seconds.\n",
      "[2021-03-16 13:29:08,907] [TfPoseEstimator] [INFO] inference image in 0.2643 seconds.\n",
      "[2021-03-16 13:29:08,928] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:29:08,928] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [6.36211777e-10 4.50370133e-01 3.98024238e-03 2.69661612e-08\n",
      " 3.96692759e-06 1.22812058e-07 5.45632052e-01 3.83362794e-06\n",
      " 9.62202949e-06]\n",
      "prediced label is : kick\n",
      "\n",
      "Processing 61th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:29:09,192] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:09,192] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:09,195] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:29:09,195] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:29:09,196] [TfPoseEstimator] [INFO] inference image in 0.2683 seconds.\n",
      "[2021-03-16 13:29:09,196] [TfPoseEstimator] [INFO] inference image in 0.2683 seconds.\n",
      "[2021-03-16 13:29:09,217] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:29:09,217] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [2.64472027e-23 2.62630617e-01 1.84600150e-04 9.09061897e-09\n",
      " 2.79573637e-13 6.62879980e-15 7.37184774e-01 2.44895123e-15\n",
      " 1.49917352e-11]\n",
      "prediced label is : kick\n",
      "\n",
      "Processing 62th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:29:09,480] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:09,480] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:09,482] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:29:09,482] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:29:09,483] [TfPoseEstimator] [INFO] inference image in 0.2653 seconds.\n",
      "[2021-03-16 13:29:09,483] [TfPoseEstimator] [INFO] inference image in 0.2653 seconds.\n",
      "[2021-03-16 13:29:09,502] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:29:09,502] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [4.58400186e-08 2.62933397e-01 7.98703965e-04 4.11295557e-08\n",
      " 2.59103894e-09 4.28761926e-07 2.37188104e-01 2.72237053e-06\n",
      " 4.99076555e-01]\n",
      "prediced label is : \n",
      "\n",
      "Processing 63th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:29:09,767] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:09,767] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:09,770] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:29:09,770] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:29:09,771] [TfPoseEstimator] [INFO] inference image in 0.2683 seconds.\n",
      "[2021-03-16 13:29:09,771] [TfPoseEstimator] [INFO] inference image in 0.2683 seconds.\n",
      "[2021-03-16 13:29:09,791] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:29:09,791] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [4.59231346e-08 4.95770583e-01 5.12856063e-03 7.46012278e-08\n",
      " 3.57530846e-09 4.28763411e-07 2.09816613e-05 2.72237054e-06\n",
      " 4.99076599e-01]\n",
      "prediced label is : \n",
      "\n",
      "Processing 64th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:29:10,053] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:10,053] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:10,056] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:29:10,056] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:29:10,057] [TfPoseEstimator] [INFO] inference image in 0.2663 seconds.\n",
      "[2021-03-16 13:29:10,057] [TfPoseEstimator] [INFO] inference image in 0.2663 seconds.\n",
      "[2021-03-16 13:29:10,078] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:29:10,078] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [8.31159624e-11 9.88109859e-01 5.11119091e-03 9.02659899e-08\n",
      " 9.84791286e-10 1.49479536e-12 6.77867983e-03 1.03020332e-14\n",
      " 1.79399609e-07]\n",
      "prediced label is : walk\n",
      "\n",
      "Processing 65th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:29:10,351] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:10,351] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:10,353] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:29:10,353] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:29:10,354] [TfPoseEstimator] [INFO] inference image in 0.2763 seconds.\n",
      "[2021-03-16 13:29:10,354] [TfPoseEstimator] [INFO] inference image in 0.2763 seconds.\n",
      "[2021-03-16 13:29:10,375] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:29:10,375] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [4.17031457e-17 9.91782114e-01 6.17414841e-04 4.80684380e-08\n",
      " 2.63191910e-13 3.44031436e-15 7.59975783e-03 4.15154717e-14\n",
      " 6.65755403e-07]\n",
      "prediced label is : walk\n",
      "\n",
      "Processing 66th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:29:10,637] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:10,637] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:10,639] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:29:10,639] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:29:10,641] [TfPoseEstimator] [INFO] inference image in 0.2663 seconds.\n",
      "[2021-03-16 13:29:10,641] [TfPoseEstimator] [INFO] inference image in 0.2663 seconds.\n",
      "[2021-03-16 13:29:10,661] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:29:10,661] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [3.51613028e-14 9.99048199e-01 2.24137974e-05 3.66137899e-10\n",
      " 3.51829266e-13 7.64216747e-17 9.28753921e-04 6.48048669e-14\n",
      " 6.32528417e-07]\n",
      "prediced label is : walk\n",
      "\n",
      "Processing 67th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:29:10,924] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:10,924] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:10,926] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:29:10,926] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:29:10,927] [TfPoseEstimator] [INFO] inference image in 0.2653 seconds.\n",
      "[2021-03-16 13:29:10,927] [TfPoseEstimator] [INFO] inference image in 0.2653 seconds.\n",
      "[2021-03-16 13:29:10,948] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:29:10,948] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [2.33841452e-09 9.99885918e-01 1.02454219e-05 8.89186295e-12\n",
      " 2.16271655e-10 6.70279462e-15 1.03103289e-04 1.81854398e-12\n",
      " 7.30382206e-07]\n",
      "prediced label is : walk\n",
      "\n",
      "Processing 68th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:29:11,208] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:11,208] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:11,210] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:29:11,210] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:29:11,211] [TfPoseEstimator] [INFO] inference image in 0.2633 seconds.\n",
      "[2021-03-16 13:29:11,211] [TfPoseEstimator] [INFO] inference image in 0.2633 seconds.\n",
      "[2021-03-16 13:29:11,232] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:29:11,232] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [7.29237956e-06 9.99902542e-01 3.00075081e-05 4.58314267e-10\n",
      " 4.60585819e-09 2.76908192e-13 1.63852567e-05 1.57775266e-10\n",
      " 4.37676391e-05]\n",
      "prediced label is : walk\n",
      "\n",
      "Processing 69th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:29:11,493] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:11,493] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:11,496] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:29:11,496] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:29:11,497] [TfPoseEstimator] [INFO] inference image in 0.2653 seconds.\n",
      "[2021-03-16 13:29:11,497] [TfPoseEstimator] [INFO] inference image in 0.2653 seconds.\n",
      "[2021-03-16 13:29:11,518] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:29:11,518] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [2.26449348e-04 9.99703273e-01 2.33230782e-05 5.65222419e-10\n",
      " 6.65046946e-09 3.64935233e-13 3.28057105e-06 1.64712083e-09\n",
      " 4.36649823e-05]\n",
      "prediced label is : walk\n",
      "\n",
      "Processing 70th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:29:11,782] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:11,782] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:11,784] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:29:11,784] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:29:11,786] [TfPoseEstimator] [INFO] inference image in 0.2683 seconds.\n",
      "[2021-03-16 13:29:11,786] [TfPoseEstimator] [INFO] inference image in 0.2683 seconds.\n",
      "[2021-03-16 13:29:11,806] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:29:11,806] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [4.96788128e-01 5.03209404e-01 1.81695740e-06 1.15857255e-10\n",
      " 1.58700115e-08 4.46347336e-13 3.11779127e-08 7.00266302e-09\n",
      " 5.96840699e-07]\n",
      "prediced label is : walk\n",
      "\n",
      "Processing 71th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:29:12,073] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:12,073] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:12,075] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:29:12,075] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:29:12,076] [TfPoseEstimator] [INFO] inference image in 0.2693 seconds.\n",
      "[2021-03-16 13:29:12,076] [TfPoseEstimator] [INFO] inference image in 0.2693 seconds.\n",
      "[2021-03-16 13:29:12,097] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:29:12,097] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [9.90291036e-01 9.69754733e-03 7.30087026e-07 1.35142734e-11\n",
      " 5.65552956e-08 1.68255759e-11 2.36062524e-09 8.77249806e-08\n",
      " 1.05401996e-05]\n",
      "prediced label is : stand\n",
      "\n",
      "Processing 72th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:29:12,359] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:12,359] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:12,361] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:29:12,361] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:29:12,362] [TfPoseEstimator] [INFO] inference image in 0.2653 seconds.\n",
      "[2021-03-16 13:29:12,362] [TfPoseEstimator] [INFO] inference image in 0.2653 seconds.\n",
      "[2021-03-16 13:29:12,383] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:29:12,383] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [9.90800081e-01 9.18794113e-03 7.12850937e-07 1.25494205e-11\n",
      " 5.68635881e-08 2.20610494e-11 2.00700350e-09 4.90203635e-07\n",
      " 1.07162157e-05]\n",
      "prediced label is : stand\n",
      "\n",
      "Processing 73th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:29:12,644] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:12,644] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:12,647] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:29:12,647] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:29:12,648] [TfPoseEstimator] [INFO] inference image in 0.2653 seconds.\n",
      "[2021-03-16 13:29:12,648] [TfPoseEstimator] [INFO] inference image in 0.2653 seconds.\n",
      "[2021-03-16 13:29:12,668] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:29:12,668] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [5.12182963e-01 4.87810221e-01 2.85838592e-06 4.39185052e-11\n",
      " 6.44471408e-08 2.50212542e-11 1.93993943e-08 3.41637557e-06\n",
      " 4.57363981e-07]\n",
      "prediced label is : stand\n",
      "\n",
      "Processing 74th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:29:12,938] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:12,938] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:12,941] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:29:12,941] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:29:12,943] [TfPoseEstimator] [INFO] inference image in 0.2753 seconds.\n",
      "[2021-03-16 13:29:12,943] [TfPoseEstimator] [INFO] inference image in 0.2753 seconds.\n",
      "[2021-03-16 13:29:12,963] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:29:12,963] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [1.04904011e-01 8.38449409e-01 5.65983453e-03 8.68531026e-08\n",
      " 1.31855299e-02 8.69456905e-04 5.40171604e-05 3.67451873e-02\n",
      " 1.32467855e-04]\n",
      "prediced label is : walk\n",
      "\n",
      "Processing 75th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:29:13,225] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:13,225] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:13,226] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:29:13,226] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:29:13,227] [TfPoseEstimator] [INFO] inference image in 0.2643 seconds.\n",
      "[2021-03-16 13:29:13,227] [TfPoseEstimator] [INFO] inference image in 0.2643 seconds.\n",
      "[2021-03-16 13:29:13,248] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:29:13,248] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [9.37048253e-02 4.73491365e-01 4.97764330e-02 2.09930520e-06\n",
      " 1.79879047e-01 5.85435919e-02 8.72857946e-04 1.43544422e-01\n",
      " 1.85358488e-04]\n",
      "prediced label is : \n",
      "\n",
      "Processing 76th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:29:13,508] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:13,508] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:13,510] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:29:13,510] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:29:13,511] [TfPoseEstimator] [INFO] inference image in 0.2623 seconds.\n",
      "[2021-03-16 13:29:13,511] [TfPoseEstimator] [INFO] inference image in 0.2623 seconds.\n",
      "[2021-03-16 13:29:13,531] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:29:13,531] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [4.99533646e-02 1.40503929e-01 4.58595993e-02 2.19315826e-06\n",
      " 2.37297739e-01 6.91394024e-02 9.06071665e-04 4.55473150e-01\n",
      " 8.64550687e-04]\n",
      "prediced label is : \n",
      "\n",
      "Processing 77th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:29:13,794] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:13,794] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:13,796] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:29:13,796] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:29:13,797] [TfPoseEstimator] [INFO] inference image in 0.2663 seconds.\n",
      "[2021-03-16 13:29:13,797] [TfPoseEstimator] [INFO] inference image in 0.2663 seconds.\n",
      "[2021-03-16 13:29:13,818] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:29:13,818] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [5.32387692e-02 6.35381744e-02 2.58412408e-03 1.67814744e-06\n",
      " 7.11550150e-02 1.25936231e-02 9.28107228e-05 7.95537768e-01\n",
      " 1.25803784e-03]\n",
      "prediced label is : punch\n",
      "\n",
      "Processing 78th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:29:14,085] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:14,085] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:14,087] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:29:14,087] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:29:14,088] [TfPoseEstimator] [INFO] inference image in 0.2703 seconds.\n",
      "[2021-03-16 13:29:14,088] [TfPoseEstimator] [INFO] inference image in 0.2703 seconds.\n",
      "[2021-03-16 13:29:14,110] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:29:14,110] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [7.19140146e-03 4.29705147e-02 1.63631770e-03 2.65830465e-06\n",
      " 2.83832105e-03 4.66804915e-01 7.72490566e-06 4.78099287e-01\n",
      " 4.48859434e-04]\n",
      "prediced label is : \n",
      "\n",
      "Processing 79th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:29:14,373] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:14,373] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:14,375] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:29:14,375] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:29:14,376] [TfPoseEstimator] [INFO] inference image in 0.2663 seconds.\n",
      "[2021-03-16 13:29:14,376] [TfPoseEstimator] [INFO] inference image in 0.2663 seconds.\n",
      "[2021-03-16 13:29:14,397] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:29:14,397] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [4.96762652e-06 6.71525143e-05 1.79346196e-03 1.43951772e-06\n",
      " 1.04144129e-01 8.03340723e-01 3.82102162e-05 9.05995637e-02\n",
      " 1.03531068e-05]\n",
      "prediced label is : squat\n",
      "\n",
      "Processing 80th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:29:14,659] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:14,659] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:14,662] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:29:14,662] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:29:14,663] [TfPoseEstimator] [INFO] inference image in 0.2653 seconds.\n",
      "[2021-03-16 13:29:14,663] [TfPoseEstimator] [INFO] inference image in 0.2653 seconds.\n",
      "[2021-03-16 13:29:14,684] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:29:14,684] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [4.73420920e-06 4.30942784e-01 4.20145200e-02 6.67076797e-04\n",
      " 1.01858593e-01 3.38402313e-01 8.16859471e-03 7.79332823e-02\n",
      " 8.10135225e-06]\n",
      "prediced label is : \n",
      "\n",
      "Processing 81th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:29:14,951] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:14,951] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:14,953] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:29:14,953] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:29:14,954] [TfPoseEstimator] [INFO] inference image in 0.2703 seconds.\n",
      "[2021-03-16 13:29:14,954] [TfPoseEstimator] [INFO] inference image in 0.2703 seconds.\n",
      "[2021-03-16 13:29:14,974] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:29:14,974] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [1.37519190e-13 4.54418887e-01 3.15829661e-01 7.55199181e-04\n",
      " 2.17167289e-04 1.75816003e-01 3.40481692e-02 1.89148932e-02\n",
      " 2.00184857e-08]\n",
      "prediced label is : \n",
      "\n",
      "Processing 82th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:29:15,247] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:15,247] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:15,249] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:29:15,249] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:29:15,250] [TfPoseEstimator] [INFO] inference image in 0.2763 seconds.\n",
      "[2021-03-16 13:29:15,250] [TfPoseEstimator] [INFO] inference image in 0.2763 seconds.\n",
      "[2021-03-16 13:29:15,270] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:29:15,270] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [2.41675541e-04 4.09883165e-02 6.22926388e-01 8.84536422e-05\n",
      " 6.26168119e-02 2.45324776e-01 2.72296184e-02 3.88767328e-04\n",
      " 1.95193018e-04]\n",
      "prediced label is : run\n",
      "\n",
      "Processing 83th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:29:15,531] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:15,531] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:15,533] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:29:15,533] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:29:15,534] [TfPoseEstimator] [INFO] inference image in 0.2643 seconds.\n",
      "[2021-03-16 13:29:15,534] [TfPoseEstimator] [INFO] inference image in 0.2643 seconds.\n",
      "[2021-03-16 13:29:15,570] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:29:15,570] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [3.03110516e-04 5.17231232e-01 3.48265820e-01 5.53522877e-08\n",
      " 6.24016939e-02 7.02469236e-02 1.31426013e-03 4.00199056e-05\n",
      " 1.96884385e-04]\n",
      "prediced label is : walk\n",
      "\n",
      "Processing 84th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:29:15,837] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:15,837] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:15,840] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:29:15,840] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:29:15,841] [TfPoseEstimator] [INFO] inference image in 0.2703 seconds.\n",
      "[2021-03-16 13:29:15,841] [TfPoseEstimator] [INFO] inference image in 0.2703 seconds.\n",
      "[2021-03-16 13:29:15,862] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:29:15,862] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [7.42933363e-05 9.99763123e-01 1.58141978e-04 2.81130857e-09\n",
      " 1.07304885e-07 2.22748987e-10 3.83521933e-07 1.02705091e-09\n",
      " 3.94706570e-06]\n",
      "prediced label is : walk\n",
      "\n",
      "Processing 85th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:29:16,125] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:16,125] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:16,127] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:29:16,127] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:29:16,128] [TfPoseEstimator] [INFO] inference image in 0.2653 seconds.\n",
      "[2021-03-16 13:29:16,128] [TfPoseEstimator] [INFO] inference image in 0.2653 seconds.\n",
      "[2021-03-16 13:29:16,149] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:29:16,149] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [1.28583622e-05 9.99979004e-01 2.58244036e-06 3.13018991e-11\n",
      " 1.30524122e-10 2.20304317e-15 3.29570221e-06 8.22569502e-11\n",
      " 2.25944178e-06]\n",
      "prediced label is : walk\n",
      "\n",
      "Processing 86th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:29:16,408] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:16,408] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:16,410] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:29:16,410] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:29:16,411] [TfPoseEstimator] [INFO] inference image in 0.2623 seconds.\n",
      "[2021-03-16 13:29:16,411] [TfPoseEstimator] [INFO] inference image in 0.2623 seconds.\n",
      "[2021-03-16 13:29:16,432] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:29:16,432] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [1.43016963e-12 9.99986383e-01 1.13106998e-07 1.21293485e-11\n",
      " 2.77478319e-13 4.08607050e-18 1.34997235e-05 4.41729472e-13\n",
      " 4.53797359e-09]\n",
      "prediced label is : walk\n",
      "\n",
      "Processing 87th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:29:16,694] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:16,694] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:16,697] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:29:16,697] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:29:16,698] [TfPoseEstimator] [INFO] inference image in 0.2663 seconds.\n",
      "[2021-03-16 13:29:16,698] [TfPoseEstimator] [INFO] inference image in 0.2663 seconds.\n",
      "[2021-03-16 13:29:16,719] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:29:16,719] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [3.90901575e-01 5.69878839e-01 3.89656666e-02 4.56093332e-10\n",
      " 2.48128112e-06 2.64058826e-11 5.28896061e-05 2.13707167e-11\n",
      " 1.98547838e-04]\n",
      "prediced label is : walk\n",
      "\n",
      "Processing 88th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:29:16,983] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:16,983] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:16,986] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:29:16,986] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:29:16,987] [TfPoseEstimator] [INFO] inference image in 0.2683 seconds.\n",
      "[2021-03-16 13:29:16,987] [TfPoseEstimator] [INFO] inference image in 0.2683 seconds.\n",
      "[2021-03-16 13:29:17,007] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:29:17,007] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [3.90924145e-01 5.64154842e-01 4.41226462e-02 5.96559477e-10\n",
      " 2.48974984e-06 2.91696270e-11 1.21831149e-04 1.60786667e-10\n",
      " 6.74044699e-04]\n",
      "prediced label is : walk\n",
      "\n",
      "Processing 89th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:29:17,268] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:17,268] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:17,270] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:29:17,270] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:29:17,271] [TfPoseEstimator] [INFO] inference image in 0.2633 seconds.\n",
      "[2021-03-16 13:29:17,271] [TfPoseEstimator] [INFO] inference image in 0.2633 seconds.\n",
      "[2021-03-16 13:29:17,307] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:29:17,307] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [2.25703283e-05 9.94140249e-01 5.15754137e-03 2.75473953e-10\n",
      " 8.46874352e-09 2.76387279e-12 2.03984171e-04 1.55227002e-10\n",
      " 4.75646256e-04]\n",
      "prediced label is : walk\n",
      "\n",
      "Processing 90th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:29:17,578] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:17,578] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:17,580] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:29:17,580] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:29:17,581] [TfPoseEstimator] [INFO] inference image in 0.2742 seconds.\n",
      "[2021-03-16 13:29:17,581] [TfPoseEstimator] [INFO] inference image in 0.2742 seconds.\n",
      "[2021-03-16 13:29:17,602] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:29:17,602] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [3.66822993e-16 4.99874538e-01 6.19182336e-07 1.84562713e-10\n",
      " 1.00963441e-14 5.64245529e-16 5.00124694e-01 1.58114055e-11\n",
      " 1.49394896e-07]\n",
      "prediced label is : kick\n",
      "\n",
      "Processing 91th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:29:17,865] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:17,865] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:17,868] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:29:17,868] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:29:17,869] [TfPoseEstimator] [INFO] inference image in 0.2673 seconds.\n",
      "[2021-03-16 13:29:17,869] [TfPoseEstimator] [INFO] inference image in 0.2673 seconds.\n",
      "[2021-03-16 13:29:17,890] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:29:17,890] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [6.22489152e-14 1.81643765e-03 3.64051285e-02 2.10577464e-06\n",
      " 6.13573115e-06 2.99244137e-03 7.45460581e-01 2.13173790e-01\n",
      " 1.43379832e-04]\n",
      "prediced label is : kick\n",
      "\n",
      "Processing 92th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:29:18,154] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:18,154] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:18,156] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:29:18,156] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:29:18,157] [TfPoseEstimator] [INFO] inference image in 0.2673 seconds.\n",
      "[2021-03-16 13:29:18,157] [TfPoseEstimator] [INFO] inference image in 0.2673 seconds.\n",
      "[2021-03-16 13:29:18,178] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:29:18,178] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [1.02914194e-13 2.01061479e-03 8.34905919e-02 4.08241511e-06\n",
      " 2.88519322e-05 1.72079643e-02 3.93187147e-01 5.03671075e-01\n",
      " 3.99673008e-04]\n",
      "prediced label is : punch\n",
      "\n",
      "Processing 93th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:29:18,442] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:18,442] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:18,444] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:29:18,444] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:29:18,446] [TfPoseEstimator] [INFO] inference image in 0.2673 seconds.\n",
      "[2021-03-16 13:29:18,446] [TfPoseEstimator] [INFO] inference image in 0.2673 seconds.\n",
      "[2021-03-16 13:29:18,465] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:29:18,465] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [7.55624355e-14 3.17962838e-04 1.35480293e-01 4.90441230e-06\n",
      " 1.49218020e-04 6.26786014e-02 2.77964851e-01 5.23065328e-01\n",
      " 3.38841295e-04]\n",
      "prediced label is : punch\n",
      "\n",
      "Processing 94th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:29:18,728] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:18,728] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:18,730] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:29:18,730] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:29:18,731] [TfPoseEstimator] [INFO] inference image in 0.2653 seconds.\n",
      "[2021-03-16 13:29:18,731] [TfPoseEstimator] [INFO] inference image in 0.2653 seconds.\n",
      "[2021-03-16 13:29:18,752] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:29:18,752] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [3.48971570e-14 7.99767173e-03 9.79498950e-02 2.97684278e-06\n",
      " 1.26501819e-04 4.84630785e-02 6.12809285e-01 2.32568043e-01\n",
      " 8.25481207e-05]\n",
      "prediced label is : kick\n",
      "\n",
      "Processing 95th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:29:19,013] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:19,013] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:19,016] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:29:19,016] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:29:19,017] [TfPoseEstimator] [INFO] inference image in 0.2653 seconds.\n",
      "[2021-03-16 13:29:19,017] [TfPoseEstimator] [INFO] inference image in 0.2653 seconds.\n",
      "[2021-03-16 13:29:19,037] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:29:19,037] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [8.81644657e-15 5.06879664e-01 9.58239970e-03 8.07623797e-08\n",
      " 1.46762593e-10 1.24488943e-12 4.83537853e-01 3.10403713e-11\n",
      " 2.29186091e-09]\n",
      "prediced label is : walk\n",
      "\n",
      "Processing 96th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:29:19,298] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:19,298] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:19,301] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:29:19,301] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:29:19,302] [TfPoseEstimator] [INFO] inference image in 0.2653 seconds.\n",
      "[2021-03-16 13:29:19,302] [TfPoseEstimator] [INFO] inference image in 0.2653 seconds.\n",
      "[2021-03-16 13:29:19,326] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:29:19,326] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [8.81654290e-15 4.99005775e-01 4.29561270e-01 3.16511019e-08\n",
      " 1.00348562e-09 7.02629904e-02 9.67674463e-04 5.72811772e-09\n",
      " 2.02251290e-04]\n",
      "prediced label is : \n",
      "\n",
      "Processing 97th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:29:19,596] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:19,596] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:19,599] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:29:19,599] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:29:19,600] [TfPoseEstimator] [INFO] inference image in 0.2743 seconds.\n",
      "[2021-03-16 13:29:19,600] [TfPoseEstimator] [INFO] inference image in 0.2743 seconds.\n",
      "[2021-03-16 13:29:19,622] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:29:19,622] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [2.45393153e-07 2.38639099e-05 9.28925851e-01 1.52982453e-07\n",
      " 3.32223375e-06 7.03250000e-02 1.22621396e-05 6.39342271e-09\n",
      " 7.09296318e-04]\n",
      "prediced label is : run\n",
      "\n",
      "Processing 98th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:29:19,916] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:19,916] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:19,919] [TfPoseEstimator] [DEBUG] estimate time=0.00199\n",
      "[2021-03-16 13:29:19,919] [TfPoseEstimator] [DEBUG] estimate time=0.00199\n",
      "[2021-03-16 13:29:19,920] [TfPoseEstimator] [INFO] inference image in 0.2982 seconds.\n",
      "[2021-03-16 13:29:19,920] [TfPoseEstimator] [INFO] inference image in 0.2982 seconds.\n",
      "[2021-03-16 13:29:19,944] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:29:19,944] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [2.45393153e-07 5.00007262e-01 4.99394830e-01 1.53055602e-07\n",
      " 3.32137680e-06 6.20095684e-05 2.51290451e-05 6.96725899e-10\n",
      " 5.07048823e-04]\n",
      "prediced label is : walk\n",
      "\n",
      "Processing 99th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:29:20,251] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:20,251] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:20,254] [TfPoseEstimator] [DEBUG] estimate time=0.00199\n",
      "[2021-03-16 13:29:20,254] [TfPoseEstimator] [DEBUG] estimate time=0.00199\n",
      "[2021-03-16 13:29:20,255] [TfPoseEstimator] [INFO] inference image in 0.3111 seconds.\n",
      "[2021-03-16 13:29:20,255] [TfPoseEstimator] [INFO] inference image in 0.3111 seconds.\n",
      "[2021-03-16 13:29:20,278] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:29:20,278] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [3.75302592e-14 9.40819796e-01 5.86400087e-02 1.52922037e-08\n",
      " 1.03183849e-12 8.93579446e-11 8.57227444e-05 3.30086030e-07\n",
      " 4.54127283e-04]\n",
      "prediced label is : walk\n",
      "\n",
      "Processing 100th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:29:20,579] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:20,579] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:20,583] [TfPoseEstimator] [DEBUG] estimate time=0.00299\n",
      "[2021-03-16 13:29:20,583] [TfPoseEstimator] [DEBUG] estimate time=0.00299\n",
      "[2021-03-16 13:29:20,584] [TfPoseEstimator] [INFO] inference image in 0.3062 seconds.\n",
      "[2021-03-16 13:29:20,584] [TfPoseEstimator] [INFO] inference image in 0.3062 seconds.\n",
      "[2021-03-16 13:29:20,608] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:29:20,608] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [1.42848102e-02 9.25031561e-01 6.00392163e-02 2.55626765e-08\n",
      " 5.51040564e-05 2.32062791e-09 1.33324173e-04 3.31574131e-07\n",
      " 4.55624300e-04]\n",
      "prediced label is : walk\n",
      "\n",
      "Processing 101th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:29:20,913] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:20,913] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:20,916] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:29:20,916] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:29:20,917] [TfPoseEstimator] [INFO] inference image in 0.3092 seconds.\n",
      "[2021-03-16 13:29:20,917] [TfPoseEstimator] [INFO] inference image in 0.3092 seconds.\n",
      "[2021-03-16 13:29:20,940] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:29:20,940] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [1.42848460e-02 9.83867300e-01 1.72823671e-03 1.07483599e-08\n",
      " 5.51660367e-05 3.19061283e-09 6.28894955e-05 3.40491995e-08\n",
      " 1.51372505e-06]\n",
      "prediced label is : walk\n",
      "\n",
      "Processing 102th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:29:21,245] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:21,245] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:21,248] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:29:21,248] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:29:21,250] [TfPoseEstimator] [INFO] inference image in 0.3102 seconds.\n",
      "[2021-03-16 13:29:21,250] [TfPoseEstimator] [INFO] inference image in 0.3102 seconds.\n",
      "[2021-03-16 13:29:21,274] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:29:21,274] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [1.75761547e-02 9.68890627e-01 4.53795384e-04 4.23037149e-07\n",
      " 9.06671202e-08 1.98147229e-08 1.69035727e-06 2.61946939e-04\n",
      " 1.28152516e-02]\n",
      "prediced label is : walk\n",
      "\n",
      "Processing 103th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:29:21,581] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:21,581] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:21,583] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:29:21,583] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:29:21,585] [TfPoseEstimator] [INFO] inference image in 0.3112 seconds.\n",
      "[2021-03-16 13:29:21,585] [TfPoseEstimator] [INFO] inference image in 0.3112 seconds.\n",
      "[2021-03-16 13:29:21,607] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:29:21,607] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [1.65811262e-01 8.16028086e-01 1.41737632e-04 4.54721150e-07\n",
      " 1.47548968e-07 3.31773281e-08 3.84340879e-08 1.84990959e-03\n",
      " 1.61683312e-02]\n",
      "prediced label is : walk\n",
      "\n",
      "Processing 104th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:29:21,919] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:21,919] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:21,922] [TfPoseEstimator] [DEBUG] estimate time=0.00199\n",
      "[2021-03-16 13:29:21,922] [TfPoseEstimator] [DEBUG] estimate time=0.00199\n",
      "[2021-03-16 13:29:21,923] [TfPoseEstimator] [INFO] inference image in 0.3161 seconds.\n",
      "[2021-03-16 13:29:21,923] [TfPoseEstimator] [INFO] inference image in 0.3161 seconds.\n",
      "[2021-03-16 13:29:21,946] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:29:21,946] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [6.47558066e-01 3.47486338e-01 1.39991146e-05 3.20795709e-08\n",
      " 1.20448419e-07 1.43221605e-08 1.10483632e-08 1.58816015e-03\n",
      " 3.35325878e-03]\n",
      "prediced label is : stand\n",
      "\n",
      "Processing 105th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:29:22,263] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:22,263] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:22,266] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:29:22,266] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:29:22,267] [TfPoseEstimator] [INFO] inference image in 0.3211 seconds.\n",
      "[2021-03-16 13:29:22,267] [TfPoseEstimator] [INFO] inference image in 0.3211 seconds.\n",
      "[2021-03-16 13:29:22,291] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:29:22,291] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [5.37469319e-01 4.51243197e-01 8.77632856e-05 1.65332112e-09\n",
      " 1.62980203e-05 1.09751102e-06 6.76699800e-07 1.11038467e-02\n",
      " 7.78004187e-05]\n",
      "prediced label is : stand\n",
      "\n",
      "Processing 106th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:29:22,593] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:22,593] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:22,595] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:29:22,595] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:29:22,597] [TfPoseEstimator] [INFO] inference image in 0.3072 seconds.\n",
      "[2021-03-16 13:29:22,597] [TfPoseEstimator] [INFO] inference image in 0.3072 seconds.\n",
      "[2021-03-16 13:29:22,637] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:29:22,637] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [3.90821838e-02 5.86975440e-01 1.35934654e-04 5.29143150e-09\n",
      " 1.85785448e-05 3.25184516e-06 1.25103480e-06 3.73371673e-01\n",
      " 4.11682076e-04]\n",
      "prediced label is : walk\n",
      "\n",
      "Processing 107th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:29:22,927] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:22,927] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:22,929] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:29:22,929] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:29:22,931] [TfPoseEstimator] [INFO] inference image in 0.2932 seconds.\n",
      "[2021-03-16 13:29:22,931] [TfPoseEstimator] [INFO] inference image in 0.2932 seconds.\n",
      "[2021-03-16 13:29:22,953] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:29:22,953] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [9.66777961e-04 1.38464028e-01 5.91239821e-05 5.48332959e-09\n",
      " 1.03962013e-05 3.05671698e-05 1.02070948e-06 8.60108125e-01\n",
      " 3.59955877e-04]\n",
      "prediced label is : punch\n",
      "\n",
      "Processing 108th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:29:23,250] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:23,250] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:23,253] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:29:23,253] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:29:23,254] [TfPoseEstimator] [INFO] inference image in 0.3002 seconds.\n",
      "[2021-03-16 13:29:23,254] [TfPoseEstimator] [INFO] inference image in 0.3002 seconds.\n",
      "[2021-03-16 13:29:23,277] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:29:23,277] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [5.38186019e-05 2.09675447e-03 2.15986061e-05 1.73282835e-08\n",
      " 1.17353299e-05 3.65049290e-04 4.79588149e-07 9.97372697e-01\n",
      " 7.78497524e-05]\n",
      "prediced label is : punch\n",
      "\n",
      "Processing 109th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:29:23,578] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:23,578] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:23,580] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:29:23,580] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:29:23,582] [TfPoseEstimator] [INFO] inference image in 0.3052 seconds.\n",
      "[2021-03-16 13:29:23,582] [TfPoseEstimator] [INFO] inference image in 0.3052 seconds.\n",
      "[2021-03-16 13:29:23,605] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:29:23,605] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [2.30021484e-05 4.22453787e-05 1.41568328e-05 1.59633944e-08\n",
      " 2.33595941e-05 3.61779156e-03 6.79520735e-08 9.96222299e-01\n",
      " 5.70617595e-05]\n",
      "prediced label is : punch\n",
      "\n",
      "Processing 110th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:29:23,899] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:23,899] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:23,903] [TfPoseEstimator] [DEBUG] estimate time=0.00299\n",
      "[2021-03-16 13:29:23,903] [TfPoseEstimator] [DEBUG] estimate time=0.00299\n",
      "[2021-03-16 13:29:23,904] [TfPoseEstimator] [INFO] inference image in 0.2992 seconds.\n",
      "[2021-03-16 13:29:23,904] [TfPoseEstimator] [INFO] inference image in 0.2992 seconds.\n",
      "[2021-03-16 13:29:23,926] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:29:23,926] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [1.86134703e-05 1.03324201e-06 9.64801289e-06 1.30828978e-09\n",
      " 1.08272458e-03 1.75010468e-02 2.51730140e-07 9.81350438e-01\n",
      " 3.62426031e-05]\n",
      "prediced label is : punch\n",
      "\n",
      "Processing 111th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:29:24,225] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:24,225] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:24,228] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:29:24,228] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:29:24,229] [TfPoseEstimator] [INFO] inference image in 0.3032 seconds.\n",
      "[2021-03-16 13:29:24,229] [TfPoseEstimator] [INFO] inference image in 0.3032 seconds.\n",
      "[2021-03-16 13:29:24,251] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:29:24,251] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [1.84403260e-05 4.80829573e-01 8.56573914e-05 1.43263421e-06\n",
      " 1.06299404e-03 1.42199269e-02 1.89886481e-02 4.84762208e-01\n",
      " 3.11204898e-05]\n",
      "prediced label is : \n",
      "\n",
      "Processing 112th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:29:24,541] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:24,541] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:24,543] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:29:24,543] [TfPoseEstimator] [DEBUG] estimate time=0.00100\n",
      "[2021-03-16 13:29:24,545] [TfPoseEstimator] [INFO] inference image in 0.2942 seconds.\n",
      "[2021-03-16 13:29:24,545] [TfPoseEstimator] [INFO] inference image in 0.2942 seconds.\n",
      "[2021-03-16 13:29:24,567] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:29:24,567] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [8.85654322e-15 9.49049960e-01 1.13433687e-03 8.64843915e-06\n",
      " 7.00951913e-07 7.97244769e-05 4.20031848e-02 7.72344143e-03\n",
      " 2.92811263e-09]\n",
      "prediced label is : walk\n",
      "\n",
      "Processing 113th image ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-16 13:29:24,857] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:24,857] [TfPoseEstimator] [DEBUG] inference- heatMat=328x184 pafMat=328x184\n",
      "[2021-03-16 13:29:24,860] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:29:24,860] [TfPoseEstimator] [DEBUG] estimate time=0.00200\n",
      "[2021-03-16 13:29:24,861] [TfPoseEstimator] [INFO] inference image in 0.2942 seconds.\n",
      "[2021-03-16 13:29:24,861] [TfPoseEstimator] [INFO] inference image in 0.2942 seconds.\n",
      "[2021-03-16 13:29:24,883] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n",
      "[2021-03-16 13:29:24,883] [TfPoseEstimator] [DEBUG] inference+ original shape=1920x1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score:\n",
      " [1.76471265e-14 4.68243872e-01 1.06781936e-01 7.22344472e-06\n",
      " 6.43207707e-04 3.92614184e-01 2.40865634e-02 7.62300900e-03\n",
      " 4.73215535e-09]\n",
      "prediced label is : \n",
      "\n",
      "Processing 114th image ...\n",
      "Complete writing 10.0fps and 11.4s video to output//walking/video.avi\n",
      "Program ends\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-fefc27fd6e77>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    346\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m             \u001b[1;31m# -- Detect skeletons\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 348\u001b[1;33m             \u001b[0mhumans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mskeleton_detector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    349\u001b[0m             \u001b[0mskeletons\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale_h\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mskeleton_detector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhumans_to_skels_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhumans\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    350\u001b[0m             \u001b[0mskeletons\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mremove_skeletons_with_few_joints\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mskeletons\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Realtime-Action-Recognition\\utils\\lib_openpose.py\u001b[0m in \u001b[0;36mdetect\u001b[1;34m(self, image)\u001b[0m\n\u001b[0;32m    116\u001b[0m         humans = self._tf_pose_estimator.inference(\n\u001b[0;32m    117\u001b[0m             \u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresize_to_default\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_w\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_h\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m             upsample_size=self._resize_out_ratio)\n\u001b[0m\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[1;31m# Print result and time cost\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf-115\\lib\\site-packages\\tf_pose\\estimator.py\u001b[0m in \u001b[0;36minference\u001b[1;34m(self, npimg, resize_to_default, upsample_size)\u001b[0m\n\u001b[0;32m    732\u001b[0m         peaks, heatMat_up, pafMat_up = self.persistent_sess.run(\n\u001b[0;32m    733\u001b[0m             \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor_peaks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor_heatMat_up\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor_pafMat_up\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 734\u001b[1;33m             \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor_image\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupsample_size\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mupsample_size\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    735\u001b[0m         )\n\u001b[0;32m    736\u001b[0m         \u001b[0mpeaks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpeaks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    954\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 956\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    957\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1178\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1180\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1181\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1357\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1359\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1360\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1363\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1365\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1366\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[1;32m-> 1350\u001b[1;33m                                       target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[0;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1443\u001b[1;33m                                             run_metadata)\n\u001b[0m\u001b[0;32m   1444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1445\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "'''\n",
    "Test action recognition on\n",
    "(1) a video, (2) a folder of images, (3) or web camera.\n",
    "\n",
    "Input:\n",
    "    model: model/trained_classifier.pickle\n",
    "\n",
    "Output:\n",
    "    result video:    output/${video_name}/video.avi\n",
    "    result skeleton: output/${video_name}/skeleton_res/XXXXX.txt\n",
    "    visualization by cv2.imshow() in img_displayer\n",
    "'''\n",
    "\n",
    "'''\n",
    "Example of usage:\n",
    "\n",
    "(1) Test on video file:\n",
    "python src/s5_test.py \\\n",
    "    --model_path model/trained_classifier.pickle \\\n",
    "    --data_type video \\\n",
    "    --data_path data_test/exercise.avi \\\n",
    "    --output_folder output\n",
    "    \n",
    "(2) Test on a folder of images:\n",
    "python src/s5_test.py \\\n",
    "    --model_path model/trained_classifier.pickle \\\n",
    "    --data_type folder \\\n",
    "    --data_path data_test/apple/ \\\n",
    "    --output_folder output\n",
    "\n",
    "(3) Test on web camera:\n",
    "python src/s5_test.py \\\n",
    "    --model_path model/trained_classifier.pickle \\\n",
    "    --data_type webcam \\\n",
    "    --data_path 0 \\\n",
    "    --output_folder output\n",
    "    \n",
    "'''\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import argparse\n",
    "if True:  # Include project path\n",
    "    import sys\n",
    "    import os\n",
    "    ROOT = os.path.dirname(os.path.abspath(\"__file__\"))+\"/../\"\n",
    "    CURR_PATH = os.path.dirname(os.path.abspath(\"__file__\"))+\"/\"\n",
    "    sys.path.append(ROOT)\n",
    "\n",
    "    import utils.lib_images_io as lib_images_io\n",
    "    import utils.lib_plot as lib_plot\n",
    "    import utils.lib_commons as lib_commons\n",
    "    from utils.lib_openpose import SkeletonDetector\n",
    "    from utils.lib_tracker import Tracker\n",
    "    from utils.lib_tracker import Tracker\n",
    "    from utils.lib_classifier import ClassifierOnlineTest\n",
    "    from utils.lib_classifier import *  # Import all sklearn related libraries\n",
    "\n",
    "\n",
    "def par(path):  # Pre-Append ROOT to the path if it's not absolute\n",
    "    return ROOT + path if (path and path[0] != \"/\") else path\n",
    "\n",
    "\n",
    "# -- Command-line input\n",
    "\n",
    "\n",
    "def get_command_line_arguments():\n",
    "\n",
    "    def parse_args():\n",
    "        parser = argparse.ArgumentParser(\n",
    "            description=\"Test action recognition on \\n\"\n",
    "            \"(1) a video, (2) a folder of images, (3) or web camera.\")\n",
    "        parser.add_argument(\"-m\", \"--model_path\", required=False,\n",
    "                            default='model/trained_classifier.pickle')\n",
    "        parser.add_argument(\"-t\", \"--data_type\", required=False, default='video',\n",
    "                            choices=[\"video\", \"folder\", \"webcam\"])\n",
    "        parser.add_argument(\"-p\", \"--data_path\", required=False, default=\"data_test/walking.mp4\",\n",
    "                            help=\"path to a video file, or images folder, or webcam. \\n\"\n",
    "                            \"For video and folder, the path should be \"\n",
    "                            \"absolute or relative to this project's root. \"\n",
    "                            \"For webcam, either input an index or device name. \")\n",
    "        parser.add_argument(\"-o\", \"--output_folder\", required=False, default='output/',\n",
    "                            help=\"Which folder to save result to.\")\n",
    "\n",
    "        #args = parser.parse_args()\n",
    "        args, unknown = parser.parse_known_args()\n",
    "        return args\n",
    "    args = parse_args()\n",
    "    if args.data_type != \"webcam\" and args.data_path and args.data_path[0] != \"/\":\n",
    "        # If the path is not absolute, then its relative to the ROOT.\n",
    "        args.data_path = ROOT + args.data_path\n",
    "    return args\n",
    "\n",
    "\n",
    "def get_dst_folder_name(src_data_type, src_data_path):\n",
    "    ''' Compute a output folder name based on data_type and data_path.\n",
    "        The final output of this script looks like this:\n",
    "            DST_FOLDER/folder_name/vidoe.avi\n",
    "            DST_FOLDER/folder_name/skeletons/XXXXX.txt\n",
    "    '''\n",
    "\n",
    "    assert(src_data_type in [\"video\", \"folder\", \"webcam\"])\n",
    "\n",
    "    if src_data_type == \"video\":  # /root/data/video.avi --> video\n",
    "        folder_name = os.path.basename(src_data_path).split(\".\")[-2]\n",
    "\n",
    "    elif src_data_type == \"folder\":  # /root/data/video/ --> video\n",
    "        folder_name = src_data_path.rstrip(\"/\").split(\"/\")[-1]\n",
    "\n",
    "    elif src_data_type == \"webcam\":\n",
    "        # month-day-hour-minute-seconds, e.g.: 02-26-15-51-12\n",
    "        folder_name = lib_commons.get_time_string()\n",
    "\n",
    "    return folder_name\n",
    "\n",
    "\n",
    "args = get_command_line_arguments()\n",
    "\n",
    "SRC_DATA_TYPE = args.data_type\n",
    "SRC_DATA_PATH = args.data_path\n",
    "SRC_MODEL_PATH = args.model_path\n",
    "\n",
    "DST_FOLDER_NAME = get_dst_folder_name(SRC_DATA_TYPE, SRC_DATA_PATH)\n",
    "\n",
    "# -- Settings\n",
    "\n",
    "cfg_all = lib_commons.read_yaml(ROOT + \"config/config.yaml\")\n",
    "cfg = cfg_all[\"s5_test.py\"]\n",
    "\n",
    "CLASSES = np.array(cfg_all[\"classes\"])\n",
    "SKELETON_FILENAME_FORMAT = cfg_all[\"skeleton_filename_format\"]\n",
    "\n",
    "# Action recognition: number of frames used to extract features.\n",
    "WINDOW_SIZE = int(cfg_all[\"features\"][\"window_size\"])\n",
    "\n",
    "# Output folder\n",
    "DST_FOLDER = args.output_folder + \"/\" + DST_FOLDER_NAME + \"/\"\n",
    "DST_SKELETON_FOLDER_NAME = cfg[\"output\"][\"skeleton_folder_name\"]\n",
    "DST_VIDEO_NAME = cfg[\"output\"][\"video_name\"]\n",
    "# framerate of output video.avi\n",
    "DST_VIDEO_FPS = float(cfg[\"output\"][\"video_fps\"])\n",
    "\n",
    "\n",
    "# Video setttings\n",
    "\n",
    "# If data_type is webcam, set the max frame rate.\n",
    "SRC_WEBCAM_MAX_FPS = float(cfg[\"settings\"][\"source\"]\n",
    "                           [\"webcam_max_framerate\"])\n",
    "\n",
    "# If data_type is video, set the sampling interval.\n",
    "# For example, if it's 3, then the video will be read 3 times faster.\n",
    "SRC_VIDEO_SAMPLE_INTERVAL = int(cfg[\"settings\"][\"source\"]\n",
    "                                [\"video_sample_interval\"])\n",
    "\n",
    "# Openpose settings\n",
    "OPENPOSE_MODEL = cfg[\"settings\"][\"openpose\"][\"model\"]\n",
    "OPENPOSE_IMG_SIZE = cfg[\"settings\"][\"openpose\"][\"img_size\"]\n",
    "\n",
    "# Display settings\n",
    "img_disp_desired_rows = int(cfg[\"settings\"][\"display\"][\"desired_rows\"])\n",
    "\n",
    "\n",
    "# -- Function\n",
    "\n",
    "\n",
    "def select_images_loader(src_data_type, src_data_path):\n",
    "    if src_data_type == \"video\":\n",
    "        images_loader = lib_images_io.ReadFromVideo(\n",
    "            src_data_path,\n",
    "            sample_interval=SRC_VIDEO_SAMPLE_INTERVAL)\n",
    "\n",
    "    elif src_data_type == \"folder\":\n",
    "        images_loader = lib_images_io.ReadFromFolder(\n",
    "            folder_path=src_data_path)\n",
    "\n",
    "    elif src_data_type == \"webcam\":\n",
    "        if src_data_path == \"\":\n",
    "            webcam_idx = 0\n",
    "        elif src_data_path.isdigit():\n",
    "            webcam_idx = int(src_data_path)\n",
    "        else:\n",
    "            webcam_idx = src_data_path\n",
    "        images_loader = lib_images_io.ReadFromWebcam(\n",
    "            SRC_WEBCAM_MAX_FPS, webcam_idx)\n",
    "    return images_loader\n",
    "\n",
    "\n",
    "class MultiPersonClassifier(object):\n",
    "    ''' This is a wrapper around ClassifierOnlineTest\n",
    "        for recognizing actions of multiple people.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, model_path, classes):\n",
    "\n",
    "        self.dict_id2clf = {}  # human id -> classifier of this person\n",
    "\n",
    "        # Define a function for creating classifier for new people.\n",
    "        self._create_classifier = lambda human_id: ClassifierOnlineTest(\n",
    "            model_path, classes, WINDOW_SIZE, human_id)\n",
    "\n",
    "    def classify(self, dict_id2skeleton):\n",
    "        ''' Classify the action type of each skeleton in dict_id2skeleton '''\n",
    "\n",
    "        # Clear people not in view\n",
    "        old_ids = set(self.dict_id2clf)\n",
    "        cur_ids = set(dict_id2skeleton)\n",
    "        humans_not_in_view = list(old_ids - cur_ids)\n",
    "        for human in humans_not_in_view:\n",
    "            del self.dict_id2clf[human]\n",
    "\n",
    "        # Predict each person's action\n",
    "        id2label = {}\n",
    "        for id, skeleton in dict_id2skeleton.items():\n",
    "\n",
    "            if id not in self.dict_id2clf:  # add this new person\n",
    "                self.dict_id2clf[id] = self._create_classifier(id)\n",
    "\n",
    "            classifier = self.dict_id2clf[id]\n",
    "            id2label[id] = classifier.predict(skeleton)  # predict label\n",
    "            # print(\"\\n\\nPredicting label for human{}\".format(id))\n",
    "            # print(\"  skeleton: {}\".format(skeleton))\n",
    "            # print(\"  label: {}\".format(id2label[id]))\n",
    "\n",
    "        return id2label\n",
    "\n",
    "    def get_classifier(self, id):\n",
    "        ''' Get the classifier based on the person id.\n",
    "        Arguments:\n",
    "            id {int or \"min\"}\n",
    "        '''\n",
    "        if len(self.dict_id2clf) == 0:\n",
    "            return None\n",
    "        if id == 'min':\n",
    "            id = min(self.dict_id2clf.keys())\n",
    "        return self.dict_id2clf[id]\n",
    "\n",
    "\n",
    "def remove_skeletons_with_few_joints(skeletons):\n",
    "    ''' Remove bad skeletons before sending to the tracker '''\n",
    "    good_skeletons = []\n",
    "    for skeleton in skeletons:\n",
    "        px = skeleton[2:2+13*2:2]\n",
    "        py = skeleton[3:2+13*2:2]\n",
    "        num_valid_joints = len([x for x in px if x != 0])\n",
    "        num_leg_joints = len([x for x in px[-6:] if x != 0])\n",
    "        total_size = max(py) - min(py)\n",
    "        # !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "        # IF JOINTS ARE MISSING, TRY CHANGING THESE VALUES:\n",
    "        # !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "        if num_valid_joints >= 5 and total_size >= 0.1 and num_leg_joints >= 0:\n",
    "            # add this skeleton only when all requirements are satisfied\n",
    "            good_skeletons.append(skeleton)\n",
    "    return good_skeletons\n",
    "\n",
    "\n",
    "def draw_result_img(img_disp, ith_img, humans, dict_id2skeleton,\n",
    "                    skeleton_detector, multiperson_classifier):\n",
    "    ''' Draw skeletons, labels, and prediction scores onto image for display '''\n",
    "\n",
    "    # Resize to a proper size for display\n",
    "    r, c = img_disp.shape[0:2]\n",
    "    desired_cols = int(1.0 * c * (img_disp_desired_rows / r))\n",
    "    img_disp = cv2.resize(img_disp,\n",
    "                          dsize=(desired_cols, img_disp_desired_rows))\n",
    "\n",
    "    # Draw all people's skeleton\n",
    "    skeleton_detector.draw(img_disp, humans)\n",
    "\n",
    "    # Draw bounding box and label of each person\n",
    "    if len(dict_id2skeleton):\n",
    "        for id, label in dict_id2label.items():\n",
    "            skeleton = dict_id2skeleton[id]\n",
    "            # scale the y data back to original\n",
    "            skeleton[1::2] = skeleton[1::2] / scale_h\n",
    "            # print(\"Drawing skeleton: \", dict_id2skeleton[id], \"with label:\", label, \".\")\n",
    "            lib_plot.draw_action_result(img_disp, id, skeleton, label)\n",
    "\n",
    "    # Add blank to the left for displaying prediction scores of each class\n",
    "    img_disp = lib_plot.add_white_region_to_left_of_image(img_disp)\n",
    "\n",
    "    cv2.putText(img_disp, \"Frame:\" + str(ith_img),\n",
    "                (20, 20), fontScale=1.5, fontFace=cv2.FONT_HERSHEY_PLAIN,\n",
    "                color=(0, 0, 0), thickness=2)\n",
    "\n",
    "    # Draw predicting score for only 1 person\n",
    "    if len(dict_id2skeleton):\n",
    "        classifier_of_a_person = multiperson_classifier.get_classifier(\n",
    "            id='min')\n",
    "        classifier_of_a_person.draw_scores_onto_image(img_disp)\n",
    "    return img_disp\n",
    "\n",
    "\n",
    "def get_the_skeleton_data_to_save_to_disk(dict_id2skeleton):\n",
    "    '''\n",
    "    In each image, for each skeleton, save the:\n",
    "        human_id, label, and the skeleton positions of length 18*2.\n",
    "    So the total length per row is 2+36=38\n",
    "    '''\n",
    "    skels_to_save = []\n",
    "    for human_id in dict_id2skeleton.keys():\n",
    "        label = dict_id2label[human_id]\n",
    "        skeleton = dict_id2skeleton[human_id]\n",
    "        skels_to_save.append([[human_id, label] + skeleton.tolist()])\n",
    "    return skels_to_save\n",
    "\n",
    "\n",
    "# -- Main\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # -- Detector, tracker, classifier\n",
    "\n",
    "    skeleton_detector = SkeletonDetector(OPENPOSE_MODEL, OPENPOSE_IMG_SIZE)\n",
    "\n",
    "    multiperson_tracker = Tracker()\n",
    "\n",
    "    multiperson_classifier = MultiPersonClassifier(SRC_MODEL_PATH, CLASSES)\n",
    "\n",
    "    # -- Image reader and displayer\n",
    "    images_loader = select_images_loader(SRC_DATA_TYPE, SRC_DATA_PATH)\n",
    "    img_displayer = lib_images_io.ImageDisplayer()\n",
    "\n",
    "    # -- Init output\n",
    "\n",
    "    # output folder\n",
    "    os.makedirs(DST_FOLDER, exist_ok=True)\n",
    "    os.makedirs(DST_FOLDER + DST_SKELETON_FOLDER_NAME, exist_ok=True)\n",
    "\n",
    "    # video writer\n",
    "    video_writer = lib_images_io.VideoWriter(\n",
    "        DST_FOLDER + DST_VIDEO_NAME, DST_VIDEO_FPS)\n",
    "\n",
    "    # -- Read images and process\n",
    "    try:\n",
    "        ith_img = -1\n",
    "        while images_loader.has_image():\n",
    "\n",
    "            # -- Read image\n",
    "            img = images_loader.read_image()\n",
    "            ith_img += 1\n",
    "            img_disp = img.copy()\n",
    "            print(f\"\\nProcessing {ith_img}th image ...\")\n",
    "\n",
    "            # -- Detect skeletons\n",
    "            humans = skeleton_detector.detect(img)\n",
    "            skeletons, scale_h = skeleton_detector.humans_to_skels_list(humans)\n",
    "            skeletons = remove_skeletons_with_few_joints(skeletons)\n",
    "\n",
    "            # -- Track people\n",
    "            dict_id2skeleton = multiperson_tracker.track(\n",
    "                skeletons)  # int id -> np.array() skeleton\n",
    "\n",
    "            # -- Recognize action of each person\n",
    "            if len(dict_id2skeleton):\n",
    "                dict_id2label = multiperson_classifier.classify(\n",
    "                    dict_id2skeleton)\n",
    "\n",
    "            # -- Draw\n",
    "            img_disp = draw_result_img(img_disp, ith_img, humans, dict_id2skeleton,\n",
    "                                       skeleton_detector, multiperson_classifier)\n",
    "\n",
    "            # Print label of a person\n",
    "            if len(dict_id2skeleton):\n",
    "                min_id = min(dict_id2skeleton.keys())\n",
    "                print(\"prediced label is :\", dict_id2label[min_id])\n",
    "\n",
    "            # -- Display image, and write to video.avi\n",
    "            img_displayer.display(img_disp, wait_key_ms=1)\n",
    "            video_writer.write(img_disp)\n",
    "\n",
    "            # -- Get skeleton data and save to file\n",
    "            skels_to_save = get_the_skeleton_data_to_save_to_disk(\n",
    "                dict_id2skeleton)\n",
    "            lib_commons.save_listlist(\n",
    "                DST_FOLDER + DST_SKELETON_FOLDER_NAME +\n",
    "                SKELETON_FILENAME_FORMAT.format(ith_img),\n",
    "                skels_to_save)\n",
    "    finally:\n",
    "        video_writer.stop()\n",
    "        print(\"Program ends\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "radical-correlation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "studied-definition",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
