{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becoming-dictionary",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import math\n",
    "\n",
    "import slidingwindow as sw\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "from tf_pose import common\n",
    "from tf_pose.common import CocoPart\n",
    "from tf_pose.tensblur.smoother import Smoother\n",
    "import tensorflow.contrib.tensorrt as trt\n",
    "\n",
    "try:\n",
    "    from tf_pose.pafprocess import pafprocess\n",
    "except ModuleNotFoundError as e:\n",
    "    print(e)\n",
    "    print(\n",
    "        \"you need to build c++ library for pafprocess. See : https://github.com/ildoonet/tf-pose-estimation/tree/master/tf_pose/pafprocess\"\n",
    "    )\n",
    "    exit(-1)\n",
    "\n",
    "logger = logging.getLogger(\"TfPoseEstimator\")\n",
    "logger.handlers.clear()\n",
    "logger.setLevel(logging.INFO)\n",
    "ch = logging.StreamHandler()\n",
    "formatter = logging.Formatter(\"[%(asctime)s] [%(name)s] [%(levelname)s] %(message)s\")\n",
    "ch.setFormatter(formatter)\n",
    "logger.addHandler(ch)\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "\n",
    "def _round(v):\n",
    "    return int(round(v))\n",
    "\n",
    "\n",
    "def _include_part(part_list, part_idx):\n",
    "    for part in part_list:\n",
    "        if part_idx == part.part_idx:\n",
    "            return True, part\n",
    "    return False, None\n",
    "\n",
    "\n",
    "class Human:\n",
    "    \"\"\"\n",
    "    body_parts: list of BodyPart\n",
    "    \"\"\"\n",
    "\n",
    "    __slots__ = (\"body_parts\", \"pairs\", \"uidx_list\", \"score\")\n",
    "\n",
    "    def __init__(self, pairs):\n",
    "        self.pairs = []\n",
    "        self.uidx_list = set()\n",
    "        self.body_parts = {}\n",
    "        for pair in pairs:\n",
    "            self.add_pair(pair)\n",
    "        self.score = 0.0\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_uidx(part_idx, idx):\n",
    "        return \"%d-%d\" % (part_idx, idx)\n",
    "\n",
    "    def add_pair(self, pair):\n",
    "        self.pairs.append(pair)\n",
    "        self.body_parts[pair.part_idx1] = BodyPart(\n",
    "            Human._get_uidx(pair.part_idx1, pair.idx1),\n",
    "            pair.part_idx1,\n",
    "            pair.coord1[0],\n",
    "            pair.coord1[1],\n",
    "            pair.score,\n",
    "        )\n",
    "        self.body_parts[pair.part_idx2] = BodyPart(\n",
    "            Human._get_uidx(pair.part_idx2, pair.idx2),\n",
    "            pair.part_idx2,\n",
    "            pair.coord2[0],\n",
    "            pair.coord2[1],\n",
    "            pair.score,\n",
    "        )\n",
    "        self.uidx_list.add(Human._get_uidx(pair.part_idx1, pair.idx1))\n",
    "        self.uidx_list.add(Human._get_uidx(pair.part_idx2, pair.idx2))\n",
    "\n",
    "    def is_connected(self, other):\n",
    "        return len(self.uidx_list & other.uidx_list) > 0\n",
    "\n",
    "    def merge(self, other):\n",
    "        for pair in other.pairs:\n",
    "            self.add_pair(pair)\n",
    "\n",
    "    def part_count(self):\n",
    "        return len(self.body_parts.keys())\n",
    "\n",
    "    def get_max_score(self):\n",
    "        return max([x.score for _, x in self.body_parts.items()])\n",
    "\n",
    "    def get_face_box(self, img_w, img_h, mode=0):\n",
    "        \"\"\"\n",
    "        Get Face box compared to img size (w, h)\n",
    "        :param img_w:\n",
    "        :param img_h:\n",
    "        :param mode:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # SEE : https://github.com/ildoonet/tf-pose-estimation/blob/master/tf_pose/common.py#L13\n",
    "        _NOSE = CocoPart.Nose.value\n",
    "        _NECK = CocoPart.Neck.value\n",
    "        _REye = CocoPart.REye.value\n",
    "        _LEye = CocoPart.LEye.value\n",
    "        _REar = CocoPart.REar.value\n",
    "        _LEar = CocoPart.LEar.value\n",
    "\n",
    "        _THRESHOLD_PART_CONFIDENCE = 0.2\n",
    "        parts = [\n",
    "            part\n",
    "            for idx, part in self.body_parts.items()\n",
    "            if part.score > _THRESHOLD_PART_CONFIDENCE\n",
    "        ]\n",
    "\n",
    "        is_nose, part_nose = _include_part(parts, _NOSE)\n",
    "        if not is_nose:\n",
    "            return None\n",
    "\n",
    "        size = 0\n",
    "        is_neck, part_neck = _include_part(parts, _NECK)\n",
    "        if is_neck:\n",
    "            size = max(size, img_h * (part_neck.y - part_nose.y) * 0.8)\n",
    "\n",
    "        is_reye, part_reye = _include_part(parts, _REye)\n",
    "        is_leye, part_leye = _include_part(parts, _LEye)\n",
    "        if is_reye and is_leye:\n",
    "            size = max(size, img_w * (part_reye.x - part_leye.x) * 2.0)\n",
    "            size = max(\n",
    "                size,\n",
    "                img_w\n",
    "                * math.sqrt(\n",
    "                    (part_reye.x - part_leye.x) ** 2 + (part_reye.y - part_leye.y) ** 2\n",
    "                )\n",
    "                * 2.0,\n",
    "            )\n",
    "\n",
    "        if mode == 1:\n",
    "            if not is_reye and not is_leye:\n",
    "                return None\n",
    "\n",
    "        is_rear, part_rear = _include_part(parts, _REar)\n",
    "        is_lear, part_lear = _include_part(parts, _LEar)\n",
    "        if is_rear and is_lear:\n",
    "            size = max(size, img_w * (part_rear.x - part_lear.x) * 1.6)\n",
    "\n",
    "        if size <= 0:\n",
    "            return None\n",
    "\n",
    "        if not is_reye and is_leye:\n",
    "            x = part_nose.x * img_w - (size // 3 * 2)\n",
    "        elif is_reye and not is_leye:\n",
    "            x = part_nose.x * img_w - (size // 3)\n",
    "        else:  # is_reye and is_leye:\n",
    "            x = part_nose.x * img_w - size // 2\n",
    "\n",
    "        x2 = x + size\n",
    "        if mode == 0:\n",
    "            y = part_nose.y * img_h - size // 3\n",
    "        else:\n",
    "            y = part_nose.y * img_h - _round(size / 2 * 1.2)\n",
    "        y2 = y + size\n",
    "\n",
    "        # fit into the image frame\n",
    "        x = max(0, x)\n",
    "        y = max(0, y)\n",
    "        x2 = min(img_w - x, x2 - x) + x\n",
    "        y2 = min(img_h - y, y2 - y) + y\n",
    "\n",
    "        if _round(x2 - x) == 0.0 or _round(y2 - y) == 0.0:\n",
    "            return None\n",
    "        if mode == 0:\n",
    "            return {\n",
    "                \"x\": _round((x + x2) / 2),\n",
    "                \"y\": _round((y + y2) / 2),\n",
    "                \"w\": _round(x2 - x),\n",
    "                \"h\": _round(y2 - y),\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                \"x\": _round(x),\n",
    "                \"y\": _round(y),\n",
    "                \"w\": _round(x2 - x),\n",
    "                \"h\": _round(y2 - y),\n",
    "            }\n",
    "\n",
    "    def get_upper_body_box(self, img_w, img_h):\n",
    "        \"\"\"\n",
    "        Get Upper body box compared to img size (w, h)\n",
    "        :param img_w:\n",
    "        :param img_h:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        if not (img_w > 0 and img_h > 0):\n",
    "            raise Exception(\"img size should be positive\")\n",
    "\n",
    "        _NOSE = CocoPart.Nose.value\n",
    "        _NECK = CocoPart.Neck.value\n",
    "        _RSHOULDER = CocoPart.RShoulder.value\n",
    "        _LSHOULDER = CocoPart.LShoulder.value\n",
    "        _THRESHOLD_PART_CONFIDENCE = 0.3\n",
    "        parts = [\n",
    "            part\n",
    "            for idx, part in self.body_parts.items()\n",
    "            if part.score > _THRESHOLD_PART_CONFIDENCE\n",
    "        ]\n",
    "        part_coords = [\n",
    "            (img_w * part.x, img_h * part.y)\n",
    "            for part in parts\n",
    "            if part.part_idx in [0, 1, 2, 5, 8, 11, 14, 15, 16, 17]\n",
    "        ]\n",
    "\n",
    "        if len(part_coords) < 5:\n",
    "            return None\n",
    "\n",
    "        # Initial Bounding Box\n",
    "        x = min([part[0] for part in part_coords])\n",
    "        y = min([part[1] for part in part_coords])\n",
    "        x2 = max([part[0] for part in part_coords])\n",
    "        y2 = max([part[1] for part in part_coords])\n",
    "\n",
    "        # # ------ Adjust heuristically +\n",
    "        # if face points are detcted, adjust y value\n",
    "\n",
    "        is_nose, part_nose = _include_part(parts, _NOSE)\n",
    "        is_neck, part_neck = _include_part(parts, _NECK)\n",
    "        torso_height = 0\n",
    "        if is_nose and is_neck:\n",
    "            y -= (part_neck.y * img_h - y) * 0.8\n",
    "            torso_height = max(0, (part_neck.y - part_nose.y) * img_h * 2.5)\n",
    "        #\n",
    "        # # by using shoulder position, adjust width\n",
    "        is_rshoulder, part_rshoulder = _include_part(parts, _RSHOULDER)\n",
    "        is_lshoulder, part_lshoulder = _include_part(parts, _LSHOULDER)\n",
    "        if is_rshoulder and is_lshoulder:\n",
    "            half_w = x2 - x\n",
    "            dx = half_w * 0.15\n",
    "            x -= dx\n",
    "            x2 += dx\n",
    "        elif is_neck:\n",
    "            if is_lshoulder and not is_rshoulder:\n",
    "                half_w = abs(part_lshoulder.x - part_neck.x) * img_w * 1.15\n",
    "                x = min(part_neck.x * img_w - half_w, x)\n",
    "                x2 = max(part_neck.x * img_w + half_w, x2)\n",
    "            elif not is_lshoulder and is_rshoulder:\n",
    "                half_w = abs(part_rshoulder.x - part_neck.x) * img_w * 1.15\n",
    "                x = min(part_neck.x * img_w - half_w, x)\n",
    "                x2 = max(part_neck.x * img_w + half_w, x2)\n",
    "\n",
    "        # ------ Adjust heuristically -\n",
    "\n",
    "        # fit into the image frame\n",
    "        x = max(0, x)\n",
    "        y = max(0, y)\n",
    "        x2 = min(img_w - x, x2 - x) + x\n",
    "        y2 = min(img_h - y, y2 - y) + y\n",
    "\n",
    "        if _round(x2 - x) == 0.0 or _round(y2 - y) == 0.0:\n",
    "            return None\n",
    "        return {\n",
    "            \"x\": _round((x + x2) / 2),\n",
    "            \"y\": _round((y + y2) / 2),\n",
    "            \"w\": _round(x2 - x),\n",
    "            \"h\": _round(y2 - y),\n",
    "        }\n",
    "\n",
    "    def __str__(self):\n",
    "        return \" \".join([str(x) for x in self.body_parts.values()])\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "\n",
    "\n",
    "class BodyPart:\n",
    "    \"\"\"\n",
    "    part_idx : part index(eg. 0 for nose)\n",
    "    x, y: coordinate of body part\n",
    "    score : confidence score\n",
    "    \"\"\"\n",
    "\n",
    "    __slots__ = (\"uidx\", \"part_idx\", \"x\", \"y\", \"score\")\n",
    "\n",
    "    def __init__(self, uidx, part_idx, x, y, score):\n",
    "        self.uidx = uidx\n",
    "        self.part_idx = part_idx\n",
    "        self.x, self.y = x, y\n",
    "        self.score = score\n",
    "\n",
    "    def get_part_name(self):\n",
    "        return CocoPart(self.part_idx)\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"BodyPart:%d-(%.2f, %.2f) score=%.2f\" % (\n",
    "            self.part_idx,\n",
    "            self.x,\n",
    "            self.y,\n",
    "            self.score,\n",
    "        )\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "\n",
    "\n",
    "class PoseEstimator:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def estimate_paf(peaks, heat_mat, paf_mat):\n",
    "        pafprocess.process_paf(peaks, heat_mat, paf_mat)\n",
    "\n",
    "        humans = []\n",
    "        for human_id in range(pafprocess.get_num_humans()):\n",
    "            human = Human([])\n",
    "            is_added = False\n",
    "\n",
    "            for part_idx in range(18):\n",
    "                c_idx = int(pafprocess.get_part_cid(human_id, part_idx))\n",
    "                if c_idx < 0:\n",
    "                    continue\n",
    "\n",
    "                is_added = True\n",
    "                human.body_parts[part_idx] = BodyPart(\n",
    "                    \"%d-%d\" % (human_id, part_idx),\n",
    "                    part_idx,\n",
    "                    float(pafprocess.get_part_x(c_idx)) / heat_mat.shape[1],\n",
    "                    float(pafprocess.get_part_y(c_idx)) / heat_mat.shape[0],\n",
    "                    pafprocess.get_part_score(c_idx),\n",
    "                )\n",
    "\n",
    "            if is_added:\n",
    "                score = pafprocess.get_score(human_id)\n",
    "                human.score = score\n",
    "                humans.append(human)\n",
    "\n",
    "        return humans\n",
    "\n",
    "\n",
    "class TfPoseEstimator:\n",
    "    # TODO : multi-scale\n",
    "\n",
    "    def __init__(\n",
    "        self, graph_path, target_size=(320, 240), tf_config=None, trt_bool=False\n",
    "    ):\n",
    "        self.target_size = target_size\n",
    "\n",
    "        # load graph\n",
    "        logger.info(\n",
    "            \"loading graph from %s(default size=%dx%d)\"\n",
    "            % (graph_path, target_size[0], target_size[1])\n",
    "        )\n",
    "        with tf.gfile.GFile(graph_path, \"rb\") as f:\n",
    "            graph_def = tf.GraphDef()\n",
    "            graph_def.ParseFromString(f.read())\n",
    "\n",
    "        if trt_bool is True:\n",
    "            output_nodes = [\"Openpose/concat_stage7\"]\n",
    "            graph_def = trt.create_inference_graph(\n",
    "                graph_def,\n",
    "                output_nodes,\n",
    "                max_batch_size=1,\n",
    "                max_workspace_size_bytes=1 << 20,\n",
    "                precision_mode=\"FP16\",\n",
    "                # precision_mode=\"INT8\",\n",
    "                minimum_segment_size=3,\n",
    "                is_dynamic_op=True,\n",
    "                maximum_cached_engines=int(1e3),\n",
    "                use_calibration=True,\n",
    "            )\n",
    "\n",
    "        self.graph = tf.get_default_graph()\n",
    "        tf.import_graph_def(graph_def, name=\"TfPoseEstimator\")\n",
    "        self.persistent_sess = tf.Session(graph=self.graph, config=tf_config)\n",
    "\n",
    "        for ts in [n.name for n in tf.get_default_graph().as_graph_def().node]:\n",
    "            print(ts)\n",
    "\n",
    "        self.tensor_image = self.graph.get_tensor_by_name(\"TfPoseEstimator/image:0\")\n",
    "        self.tensor_output = self.graph.get_tensor_by_name(\n",
    "            \"TfPoseEstimator/Openpose/concat_stage7:0\"\n",
    "        )\n",
    "        self.tensor_heatMat = self.tensor_output[:, :, :, :19]\n",
    "        self.tensor_pafMat = self.tensor_output[:, :, :, 19:]\n",
    "        self.upsample_size = tf.placeholder(\n",
    "            dtype=tf.int32, shape=(2,), name=\"upsample_size\"\n",
    "        )\n",
    "        self.tensor_heatMat_up = tf.image.resize_area(\n",
    "            self.tensor_output[:, :, :, :19],\n",
    "            self.upsample_size,\n",
    "            align_corners=False,\n",
    "            name=\"upsample_heatmat\",\n",
    "        )\n",
    "        self.tensor_pafMat_up = tf.image.resize_area(\n",
    "            self.tensor_output[:, :, :, 19:],\n",
    "            self.upsample_size,\n",
    "            align_corners=False,\n",
    "            name=\"upsample_pafmat\",\n",
    "        )\n",
    "        if trt_bool is True:\n",
    "            smoother = Smoother({\"data\": self.tensor_heatMat_up}, 25, 3.0, 19)\n",
    "        else:\n",
    "            smoother = Smoother({\"data\": self.tensor_heatMat_up}, 25, 3.0)\n",
    "        gaussian_heatMat = smoother.get_output()\n",
    "\n",
    "        max_pooled_in_tensor = tf.nn.pool(\n",
    "            gaussian_heatMat, window_shape=(3, 3), pooling_type=\"MAX\", padding=\"SAME\"\n",
    "        )\n",
    "        self.tensor_peaks = tf.where(\n",
    "            tf.equal(gaussian_heatMat, max_pooled_in_tensor),\n",
    "            gaussian_heatMat,\n",
    "            tf.zeros_like(gaussian_heatMat),\n",
    "        )\n",
    "\n",
    "        self.heatMat = self.pafMat = None\n",
    "\n",
    "        # warm-up\n",
    "        self.persistent_sess.run(\n",
    "            tf.variables_initializer(\n",
    "                [\n",
    "                    v\n",
    "                    for v in tf.global_variables()\n",
    "                    if v.name.split(\":\")[0]\n",
    "                    in [\n",
    "                        x.decode(\"utf-8\")\n",
    "                        for x in self.persistent_sess.run(\n",
    "                            tf.report_uninitialized_variables()\n",
    "                        )\n",
    "                    ]\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "        self.persistent_sess.run(\n",
    "            [self.tensor_peaks, self.tensor_heatMat_up, self.tensor_pafMat_up],\n",
    "            feed_dict={\n",
    "                self.tensor_image: [\n",
    "                    np.ndarray(\n",
    "                        shape=(target_size[1], target_size[0], 3), dtype=np.float32\n",
    "                    )\n",
    "                ],\n",
    "                self.upsample_size: [target_size[1], target_size[0]],\n",
    "            },\n",
    "        )\n",
    "        self.persistent_sess.run(\n",
    "            [self.tensor_peaks, self.tensor_heatMat_up, self.tensor_pafMat_up],\n",
    "            feed_dict={\n",
    "                self.tensor_image: [\n",
    "                    np.ndarray(\n",
    "                        shape=(target_size[1], target_size[0], 3), dtype=np.float32\n",
    "                    )\n",
    "                ],\n",
    "                self.upsample_size: [target_size[1] // 2, target_size[0] // 2],\n",
    "            },\n",
    "        )\n",
    "        self.persistent_sess.run(\n",
    "            [self.tensor_peaks, self.tensor_heatMat_up, self.tensor_pafMat_up],\n",
    "            feed_dict={\n",
    "                self.tensor_image: [\n",
    "                    np.ndarray(\n",
    "                        shape=(target_size[1], target_size[0], 3), dtype=np.float32\n",
    "                    )\n",
    "                ],\n",
    "                self.upsample_size: [target_size[1] // 4, target_size[0] // 4],\n",
    "            },\n",
    "        )\n",
    "\n",
    "        # logs\n",
    "        if self.tensor_image.dtype == tf.quint8:\n",
    "            logger.info(\"quantization mode enabled.\")\n",
    "\n",
    "    def __del__(self):\n",
    "        # self.persistent_sess.close()\n",
    "        pass\n",
    "\n",
    "    def get_flops(self):\n",
    "        flops = tf.profiler.profile(\n",
    "            self.graph, options=tf.profiler.ProfileOptionBuilder.float_operation()\n",
    "        )\n",
    "        return flops.total_float_ops\n",
    "\n",
    "    @staticmethod\n",
    "    def _quantize_img(npimg):\n",
    "        npimg_q = npimg + 1.0\n",
    "        npimg_q /= 2.0 / 2 ** 8\n",
    "        # npimg_q += 0.5\n",
    "        npimg_q = npimg_q.astype(np.uint8)\n",
    "        return npimg_q\n",
    "\n",
    "    @staticmethod\n",
    "    def draw_humans(npimg, humans, imgcopy=False):\n",
    "        if imgcopy:\n",
    "            npimg = np.copy(npimg)\n",
    "        image_h, image_w = npimg.shape[:2]\n",
    "        centers = {}\n",
    "        for human in humans:\n",
    "            # draw point\n",
    "            for i in range(common.CocoPart.Background.value):\n",
    "                if i not in human.body_parts.keys():\n",
    "                    continue\n",
    "\n",
    "                body_part = human.body_parts[i]\n",
    "                center = (\n",
    "                    int(body_part.x * image_w + 0.5),\n",
    "                    int(body_part.y * image_h + 0.5),\n",
    "                )\n",
    "                centers[i] = center\n",
    "                cv2.circle(\n",
    "                    npimg,\n",
    "                    center,\n",
    "                    3,\n",
    "                    common.CocoColors[i],\n",
    "                    thickness=3,\n",
    "                    lineType=8,\n",
    "                    shift=0,\n",
    "                )\n",
    "\n",
    "            # draw line\n",
    "            for pair_order, pair in enumerate(common.CocoPairsRender):\n",
    "                if (\n",
    "                    pair[0] not in human.body_parts.keys()\n",
    "                    or pair[1] not in human.body_parts.keys()\n",
    "                ):\n",
    "                    continue\n",
    "\n",
    "                # npimg = cv2.line(npimg, centers[pair[0]], centers[pair[1]], common.CocoColors[pair_order], 3)\n",
    "                cv2.line(\n",
    "                    npimg,\n",
    "                    centers[pair[0]],\n",
    "                    centers[pair[1]],\n",
    "                    common.CocoColors[pair_order],\n",
    "                    3,\n",
    "                )\n",
    "\n",
    "        return npimg\n",
    "\n",
    "    def _get_scaled_img(self, npimg, scale):\n",
    "        get_base_scale = (\n",
    "            lambda s, w, h: max(\n",
    "                self.target_size[0] / float(h), self.target_size[1] / float(w)\n",
    "            )\n",
    "            * s\n",
    "        )\n",
    "        img_h, img_w = npimg.shape[:2]\n",
    "\n",
    "        if scale is None:\n",
    "            if npimg.shape[:2] != (self.target_size[1], self.target_size[0]):\n",
    "                # resize\n",
    "                npimg = cv2.resize(\n",
    "                    npimg, self.target_size, interpolation=cv2.INTER_CUBIC\n",
    "                )\n",
    "            return [npimg], [(0.0, 0.0, 1.0, 1.0)]\n",
    "        elif isinstance(scale, float):\n",
    "            # scaling with center crop\n",
    "            base_scale = get_base_scale(scale, img_w, img_h)\n",
    "            npimg = cv2.resize(\n",
    "                npimg,\n",
    "                dsize=None,\n",
    "                fx=base_scale,\n",
    "                fy=base_scale,\n",
    "                interpolation=cv2.INTER_CUBIC,\n",
    "            )\n",
    "\n",
    "            o_size_h, o_size_w = npimg.shape[:2]\n",
    "            if (\n",
    "                npimg.shape[0] < self.target_size[1]\n",
    "                or npimg.shape[1] < self.target_size[0]\n",
    "            ):\n",
    "                newimg = np.zeros(\n",
    "                    (\n",
    "                        max(self.target_size[1], npimg.shape[0]),\n",
    "                        max(self.target_size[0], npimg.shape[1]),\n",
    "                        3,\n",
    "                    ),\n",
    "                    dtype=np.uint8,\n",
    "                )\n",
    "                newimg[: npimg.shape[0], : npimg.shape[1], :] = npimg\n",
    "                npimg = newimg\n",
    "\n",
    "            windows = sw.generate(\n",
    "                npimg,\n",
    "                sw.DimOrder.HeightWidthChannel,\n",
    "                self.target_size[0],\n",
    "                self.target_size[1],\n",
    "                0.2,\n",
    "            )\n",
    "\n",
    "            rois = []\n",
    "            ratios = []\n",
    "            for window in windows:\n",
    "                indices = window.indices()\n",
    "                roi = npimg[indices]\n",
    "                rois.append(roi)\n",
    "                ratio_x, ratio_y = (\n",
    "                    float(indices[1].start) / o_size_w,\n",
    "                    float(indices[0].start) / o_size_h,\n",
    "                )\n",
    "                ratio_w, ratio_h = (\n",
    "                    float(indices[1].stop - indices[1].start) / o_size_w,\n",
    "                    float(indices[0].stop - indices[0].start) / o_size_h,\n",
    "                )\n",
    "                ratios.append((ratio_x, ratio_y, ratio_w, ratio_h))\n",
    "\n",
    "            return rois, ratios\n",
    "        elif isinstance(scale, tuple) and len(scale) == 2:\n",
    "            # scaling with sliding window : (scale, step)\n",
    "            base_scale = get_base_scale(scale[0], img_w, img_h)\n",
    "            npimg = cv2.resize(\n",
    "                npimg,\n",
    "                dsize=None,\n",
    "                fx=base_scale,\n",
    "                fy=base_scale,\n",
    "                interpolation=cv2.INTER_CUBIC,\n",
    "            )\n",
    "            o_size_h, o_size_w = npimg.shape[:2]\n",
    "            if (\n",
    "                npimg.shape[0] < self.target_size[1]\n",
    "                or npimg.shape[1] < self.target_size[0]\n",
    "            ):\n",
    "                newimg = np.zeros(\n",
    "                    (\n",
    "                        max(self.target_size[1], npimg.shape[0]),\n",
    "                        max(self.target_size[0], npimg.shape[1]),\n",
    "                        3,\n",
    "                    ),\n",
    "                    dtype=np.uint8,\n",
    "                )\n",
    "                newimg[: npimg.shape[0], : npimg.shape[1], :] = npimg\n",
    "                npimg = newimg\n",
    "\n",
    "            window_step = scale[1]\n",
    "\n",
    "            windows = sw.generate(\n",
    "                npimg,\n",
    "                sw.DimOrder.HeightWidthChannel,\n",
    "                self.target_size[0],\n",
    "                self.target_size[1],\n",
    "                window_step,\n",
    "            )\n",
    "\n",
    "            rois = []\n",
    "            ratios = []\n",
    "            for window in windows:\n",
    "                indices = window.indices()\n",
    "                roi = npimg[indices]\n",
    "                rois.append(roi)\n",
    "                ratio_x, ratio_y = (\n",
    "                    float(indices[1].start) / o_size_w,\n",
    "                    float(indices[0].start) / o_size_h,\n",
    "                )\n",
    "                ratio_w, ratio_h = (\n",
    "                    float(indices[1].stop - indices[1].start) / o_size_w,\n",
    "                    float(indices[0].stop - indices[0].start) / o_size_h,\n",
    "                )\n",
    "                ratios.append((ratio_x, ratio_y, ratio_w, ratio_h))\n",
    "\n",
    "            return rois, ratios\n",
    "        elif isinstance(scale, tuple) and len(scale) == 3:\n",
    "            # scaling with ROI : (want_x, want_y, scale_ratio)\n",
    "            base_scale = get_base_scale(scale[2], img_w, img_h)\n",
    "            npimg = cv2.resize(\n",
    "                npimg,\n",
    "                dsize=None,\n",
    "                fx=base_scale,\n",
    "                fy=base_scale,\n",
    "                interpolation=cv2.INTER_CUBIC,\n",
    "            )\n",
    "            ratio_w = self.target_size[0] / float(npimg.shape[1])\n",
    "            ratio_h = self.target_size[1] / float(npimg.shape[0])\n",
    "\n",
    "            want_x, want_y = scale[:2]\n",
    "            ratio_x = want_x - ratio_w / 2.0\n",
    "            ratio_y = want_y - ratio_h / 2.0\n",
    "            ratio_x = max(ratio_x, 0.0)\n",
    "            ratio_y = max(ratio_y, 0.0)\n",
    "            if ratio_x + ratio_w > 1.0:\n",
    "                ratio_x = 1.0 - ratio_w\n",
    "            if ratio_y + ratio_h > 1.0:\n",
    "                ratio_y = 1.0 - ratio_h\n",
    "\n",
    "            roi = self._crop_roi(npimg, ratio_x, ratio_y)\n",
    "            return [roi], [(ratio_x, ratio_y, ratio_w, ratio_h)]\n",
    "\n",
    "    def _crop_roi(self, npimg, ratio_x, ratio_y):\n",
    "        target_w, target_h = self.target_size\n",
    "        h, w = npimg.shape[:2]\n",
    "        x = max(int(w * ratio_x - 0.5), 0)\n",
    "        y = max(int(h * ratio_y - 0.5), 0)\n",
    "        cropped = npimg[y : y + target_h, x : x + target_w]\n",
    "\n",
    "        cropped_h, cropped_w = cropped.shape[:2]\n",
    "        if cropped_w < target_w or cropped_h < target_h:\n",
    "            npblank = np.zeros(\n",
    "                (self.target_size[1], self.target_size[0], 3), dtype=np.uint8\n",
    "            )\n",
    "\n",
    "            copy_x, copy_y = (target_w - cropped_w) // 2, (target_h - cropped_h) // 2\n",
    "            npblank[copy_y : copy_y + cropped_h, copy_x : copy_x + cropped_w] = cropped\n",
    "        else:\n",
    "            return cropped\n",
    "\n",
    "    def inference(self, npimg, resize_to_default=True, upsample_size=1.0):\n",
    "        if npimg is None:\n",
    "            raise Exception(\"The image is not valid. Please check your image exists.\")\n",
    "\n",
    "        if resize_to_default:\n",
    "            upsample_size = [\n",
    "                int(self.target_size[1] / 8 * upsample_size),\n",
    "                int(self.target_size[0] / 8 * upsample_size),\n",
    "            ]\n",
    "        else:\n",
    "            upsample_size = [\n",
    "                int(npimg.shape[0] / 8 * upsample_size),\n",
    "                int(npimg.shape[1] / 8 * upsample_size),\n",
    "            ]\n",
    "\n",
    "        if self.tensor_image.dtype == tf.quint8:\n",
    "            # quantize input image\n",
    "            npimg = TfPoseEstimator._quantize_img(npimg)\n",
    "            pass\n",
    "\n",
    "        logger.debug(\n",
    "            \"inference+ original shape=%dx%d\" % (npimg.shape[1], npimg.shape[0])\n",
    "        )\n",
    "        img = npimg\n",
    "        if resize_to_default:\n",
    "            img = self._get_scaled_img(npimg, None)[0][0]\n",
    "        peaks, heatMat_up, pafMat_up = self.persistent_sess.run(\n",
    "            [self.tensor_peaks, self.tensor_heatMat_up, self.tensor_pafMat_up],\n",
    "            feed_dict={self.tensor_image: [img], self.upsample_size: upsample_size},\n",
    "        )\n",
    "        peaks = peaks[0]\n",
    "        self.heatMat = heatMat_up[0]\n",
    "        self.pafMat = pafMat_up[0]\n",
    "        logger.debug(\n",
    "            \"inference- heatMat=%dx%d pafMat=%dx%d\"\n",
    "            % (\n",
    "                self.heatMat.shape[1],\n",
    "                self.heatMat.shape[0],\n",
    "                self.pafMat.shape[1],\n",
    "                self.pafMat.shape[0],\n",
    "            )\n",
    "        )\n",
    "\n",
    "        t = time.time()\n",
    "        humans = PoseEstimator.estimate_paf(peaks, self.heatMat, self.pafMat)\n",
    "        logger.debug(\"estimate time=%.5f\" % (time.time() - t))\n",
    "        return humans\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import pickle\n",
    "\n",
    "    f = open(\"./etcs/heatpaf1.pkl\", \"rb\")\n",
    "    data = pickle.load(f)\n",
    "    logger.info(\"size={}\".format(data[\"heatMat\"].shape))\n",
    "    f.close()\n",
    "\n",
    "    t = time.time()\n",
    "    humans = PoseEstimator.estimate_paf(data[\"peaks\"], data[\"heatMat\"], data[\"pafMat\"])\n",
    "    dt = time.time() - t\n",
    "    t = time.time()\n",
    "    logger.info(\"elapsed #humans=%d time=%.8f\" % (len(humans), dt))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
